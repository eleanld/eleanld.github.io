<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>内容聚合首页 - 精选优质内容</title>
    <meta name="description" content="自动聚合各大网站优质内容，每日更新，包含科技、知识、编程等多个分类">
    <meta name="keywords" content="内容聚合,RSS,新闻,博客,科技,知识,编程">
    <link rel="stylesheet" href="/static/css/style.css">
</head>
<body>

<!-- 百度联盟横幅广告 -->
<div style="margin: 10px auto; text-align: center;">
    <script type="text/javascript">
        (function() {
            var s = "_" + Math.random().toString(36).slice(2);
            document.write('<div id="' + s + '"></div>');
            (window.slotbydup=window.slotbydup || []).push({
                id: 'ele',
                container: s,
                size: '728,90',
                display: 'inlay-fix'
            });
        })();
    </script>
    <script type="text/javascript" src="//cpro.baidustatic.com/cpro/ui/c.js" async="async" defer="defer"></script>
</div>

    <header>
        <div class="container">
            <h1>内容聚合平台</h1>
            <nav>
                <ul>
                    <li><a href="/">首页</a></li>
                    
                    <li><a href="/category/知识/">知识</a></li>
                    
                    <li><a href="/category/编程/">编程</a></li>
                    
                    <li><a href="/category/科技/">科技</a></li>
                    
                </ul>
            </nav>
        </div>
    </header>
    
    <main class="container">
        
<h2>最新内容</h2>

<div class="articles">
    
    <article class="article-item">
        <h3><a href="/article/761c95f4660920404181b96ef11b1d28.html">始祖鸟，在澳门购物中心建了一座「悬崖庇护所」</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Wed, 26 Feb 2025 09:35:53 +0000</span>
        </div>
        <div class="article-summary">
            把山野装进生活的每个褶皱。<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615439">原文链接</a> ·
<a href="https://www.ifanr.com/1615439#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/761c95f4660920404181b96ef11b1d28.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615439?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/b60dd44c2e26a420ff2f8e1887549277.html">一文看懂 DeepSeek 开源项目第三弹，300 行代码揭示 V3/R1 推理效率背后的关键</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Wed, 26 Feb 2025 02:58:08 +0000</span>
        </div>
        <div class="article-summary">
            DeepSeek 开源项目第三弹来了<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615619">原文链接</a> ·
<a href="https://www.ifanr.com/1615619#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/b60dd44c2e26a420ff2f8e1887549277.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615619?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/.html"></a></h3>
        <div class="article-meta">
            <span class="category"></span>
            <span class="date"></span>
        </div>
        <div class="article-summary">
            
        </div>
        <div class="article-link">
            <a href="/article/.html">阅读全文</a>
            <a href="" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/b15e1567227fa5672ec232d188a61699.html">叔叔我当年挑着电脑主机，在移动办公界 chuang 出一片天地</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Wed, 26 Feb 2025 02:14:38 +0000</span>
        </div>
        <div class="article-summary">
            扛不动别硬扛。<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615640">原文链接</a> ·
<a href="https://www.ifanr.com/1615640#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/b15e1567227fa5672ec232d188a61699.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615640?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/2989021e02056d0721445aa79ed797c0.html">早报|微信电脑端支持接收红包/江汽回应尊界租车暴力测试传闻/理想纯电车型亮相，雷军转发</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Wed, 26 Feb 2025 00:41:43 +0000</span>
        </div>
        <div class="article-summary">
            · 字节豆包小范围测试深度思考模型
· DeepSeek R2 或提前推出
· 星巴克：全球裁员不涉及中国区<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615616">原文链接</a> ·
<a href="https://www.ifanr.com/1615616#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/2989021e02056d0721445aa79ed797c0.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615616?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/5dde8cb1ff5f096692e8a7c4d0f07dbc.html">已经掌握独立建造第三代核电站的技术的国家有哪些？</a></h3>
        <div class="article-meta">
            <span class="category">知识</span>
            <span class="date">Wed, 25 Sep 2024 18:30:53 +0800</span>
        </div>
        <div class="article-summary">
            <p>谢邀 <a class="member_mention" href="https://www.zhihu.com/people/2fa0d82713f499ce1373dc02a19d02fd">@央视新闻</a> </p><p>我是“华龙一号”总设计师邢继。10年之后的我们，可以非常确定地回答题主：</p><p><b>这个名单里，有中国。</b></p><p><img src="https://pic1.zhimg.com/v2-8b4b8102e00d8072e61a88b84e94c595_720w.jpg?source=b1748391?rss" /></p><p>这是一道来自2011年6月的提问，就在这道问题提出的3个月前，我们中国自主的百万千万级核电技术的梦想，刚刚被一场发生在日本福岛的核泄漏事故击得粉碎。</p><p>那时候，承载了几代核工业人梦想的型号CP1000即将开工，10多台推土机已经抵达现场开始挖土，仅仅3天之后，事故发生，项目被按下了暂停键。</p><p>福岛核事故对整个核工业发展的影响非常深远。中国作为一个负责任的大国，在核事故发生5天后，国务院发出声明，针对核安全问题提出四条指导性意见，其中有一条就是 中国未来新建的核电站必须满足国际最高安全标准。</p><p>中核集团在第一时间组织专家进行评估后，主动放弃了CP1000，转向全力推进第三代核电技术ACP1000，也就是后来“华龙一号”的自主研发。</p><p>放弃“CP1000”，这个决心下得非常果断，我们的核电站必须要能够应对所有“假设可能会发生”的事情，此前我们的目标离“要达到国际上最高要求”的这个标准还有距离。</p><p>因此，团队受到了相当大的打击。一个准备了12年的计划马上就可以实现，但在下一个瞬间，它变得遥遥无期。</p><p>为什么大家如此沮丧？</p><p><b>因为研发一个完全具有自主知识产权的型号，是我们中国核电人的梦想。</b></p><p>1989年，我被派往广东，那时候大亚湾核电站刚刚开工，我所在的核二院派了100多人到业主单位和法国公司参与建设。我被派到了法国公司的现场技术部做现场施工方面的技术支持。</p><p>大亚湾核电站主要的技术全是来自于法国，在装备建造这些领域也主要依靠外国人的技术和管理，甚至连一些最基本的钢筋、水泥等建设材料，都要从外国进口，长期受制于人，感受非常真实。</p><p>在这个庞大的工程里，我们需要从零开始，读懂法国人设计的每一张图纸，见缝插针地问各种原理性的问题：为什么要这么设计，遵循了怎样的标准？</p><p>年轻时候在大亚湾的这段经历，给我的触动非常深刻。彼时，我国核电领域在设计、建造与管理上的能力尚处于萌芽阶段，中核集团赋予我们的使命，便是踏上这片技术的沃土，虚心学习并汲取先进技术的精髓。我国核电的发展从一开始起步就确定了自主之路。</p><p>在学习与合作的过程中还有许多插曲。我记得有一次跟外方的负责人讨论某项技术，我发现这个型号的转让技术资料不完整，请对方讨论如何补充完善，同时商量怎么让我们中国工程师尽快掌握技术，进行自主设计。</p><p>外方负责人讲了一句话，我至今都记得很清楚：你们不用研究这些事情，要想知道核电站怎么设计，让你的工程师放下手中的铅笔，去打开复印机，你们就会了。你只要去复印我们的资料，不用搞清楚里面的原因。</p><p>我当时非常生气：“如果你不打开你的‘黑匣子’，我们可以不要你的技术转让。”这次冲突让我体会到，尽管我们引进了国际上先进的技术，签了协议，交了学费，但因为核心技术被别人掌握，我们甚至没有跟别人争辩的权利。</p><p><b>这样的事情太多太多，被卡住脖子的滋味，太难受。</b></p><p>引进、吸收、消化国际先进技术只是第一步，know how以外更核心的是know why。</p><p>我们深刻地认识到，真正的核心技术，靠金钱买不来，靠市场换不来，只有自主研发，我们必须要把核能未来的发展技术掌握到自己的手里，而这条路没有捷径。</p><p>所以当CP1000停工之后，我们立即调整状态，全力以赴投入到三代核电技术研发当中。</p><p>曾经我们投注在CP1000上的心血，没有白费，用另一种方式扎下了根。</p><p>“华龙一号”是一个里程碑，标志着中国核电技术进入了世界先进国家行列。其自主创新不仅限于研发设计与安全理论的深度挖掘，更涵盖了安全分析技术的方法与工具等全方位创新，这是一场系统性、全面性的技术革新。</p><p>在设计思路上，“华龙一号”机组对标国际最先进的三代核电技术，充分考虑到了各种可能出现的极端情况，确保即便地震和海啸叠加发生，也能保证安全。我们提出了能动与非能动相结合，设置了多样化的手段来实现余热的导出和放射性的包容；通过双层安全壳等一系列设计，全面地满足国际上最高的安全标准，外层可抵御大飞机的撞击，内层做到即使堆芯出现问题，放射性物质也不会泄漏出来。</p><p>“华龙一号”首次实现了真正意义上的所有元素均基于正向设计的理念。在研发过程中，我们开展产学研合作，在“华龙一号”的关键核心设备上实现100%设备自主化、国产化，不仅关键设备，核电建设用的大宗材料也是如此。我们超越了推理模仿复制的层面，实现了从“知其然”到“知其所以然”的蜕变。以安全级电缆的热缩套管为例，这一领域曾长期被国外某企业独占市场，但通过我们与国内企业的共同努力，成功研发出适用于“华龙一号”严重事故场景下的电缆热缩套管，不仅打破了垄断，还实现了成本的大幅降低，其价格仅为国外同类产品的五分之一。</p><h2>从水泥、电话线都要从国外进口，到实现先进核电堆型首堆68.7个月的最短建设工期，我们靠自己的力量翻越了一座又一座山，实现了我国核电技术从跟跑到并跑的跨越性发展。后来的故事，大家都知道了。</h2><p>如今，“华龙一号”已步入批量化建设阶段，国内外在运、在建机组总数达到33台，已成为全球在运在建机组总数最多的三代核电技术。我们没有满足于现在的成绩，还在持续研究如何进一步优化“华龙一号”的设计，在保障安全性的基础上，让经济性进一步提升。</p><p><img src="https://picx.zhimg.com/v2-a695847e0e6e57c6e8389e1a40116430_720w.jpg?source=b1748391?rss" /></p><p>正在开展的“华龙一号”后续机型相关验证试验，不断传来好消息。从指标上来看，它的安全性依然比国际上三代要求高一个量级，经济性优于今天的“华龙一号”批量化目标，同时，其建设工期大幅度缩短到50个月以内。不仅如此，它的电厂可用率和电厂设计寿期都得到了提高。</p><p>我听说过一个小故事。很多年前，909厂的核潜艇陆上模式堆发出了中国核能的第一度电，后来，在拆除屏蔽墙的过程中，年轻的工程师们在铅块底下发现了这样一句跨越时空的问候：“孩子们，辛苦了。”</p><p>我们不知道是谁偷偷写下了这句话，但那时的他们一定与如今的我们一样，期待着蓝色光芒的闪烁，期待着中国核工业的远航。同样，我们也希望通过现在的努力，让后来者站在我们的肩膀上眺望。</p><p>一代人有一代人的使命，核工业这个行业从诞生的那一天起就跟“科技自立自强”紧密相关，它是血脉的传承，自主创新，就是我们这一代核电工程师的使命与考验。中国自主的核电技术已经进入世界的第一阵营，竞争还在继续，领跑只是开始。</p><p>中“华”复兴，巨“龙”腾飞。“华龙一号”这个名字，代表了一种深沉的期许。我们是龙的传人，注定走向强大。强核报国，创新奉献，相信这样的精神会在核工业行业一代一代地传承下去。</p>
<br /><br />
来源：知乎 www.zhihu.com<br />
    
作者：<a href="http://www.zhihu.com/people/57-2-33-25?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=author">邢继</a><br />
            
<br />
【知乎日报】千万用户的选择，做朋友圈里的新鲜事分享大牛。
        <a href="http://daily.zhihu.com?utm_source=rssyanwenzi&amp;utm_campaign=tuijian&amp;utm_medium=rssnormal" target="_blank">点击下载</a><br />
<br />
此问题还有 <a href="http://www.zhihu.com/question/19700567/answer/3635928923?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">40 个回答，查看全部。</a><br />
                延伸阅读：<br />
<a href="http://www.zhihu.com/question/278357130?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">如何评价「中国自主核电站神经中枢实现百万千瓦级核电工程首台套应用」？</a><br />
            
<a href="http://www.zhihu.com/question/292431114?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">如何评价内陆核电站的发展？</a><br />
        </div>
        <div class="article-link">
            <a href="/article/5dde8cb1ff5f096692e8a7c4d0f07dbc.html">阅读全文</a>
            <a href="http://www.zhihu.com/question/19700567/answer/3635928923?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/d776a5ecc6ec11683813bb23cda98f8f.html">Reverse-o1:OpenAI o1原理逆向工程图解</a></h3>
        <div class="article-meta">
            <span class="category">知识</span>
            <span class="date">Wed, 25 Sep 2024 11:23:03 +0800</span>
        </div>
        <div class="article-summary">
            <p>OpenAI o1的推出称为横空出世不为过，尽管关于Q*、草莓等各种传闻很久了，用了强化学习增强逻辑推理能力这个大方向大家猜的也八九不离十，但是融合LLM和RL来生成Hidden COT，估计很少人能想到这点，而且目前看效果确实挺好的。</p><p>OpenAI奔向Close的路上越走越远，你要从o1官宣字面来看，除了“强化学习生成Hidden COT”外，基本找不到其它有技术含量的内容。Sora好歹还给出了个粗略的技术框架图，字里行间也透漏不少隐含的技术点，细心点总能发现很多蛛丝马迹，串起来之后整个背后的技术就若隐若现（若对此感兴趣可看下我之前写的分析：<a class="internal" href="https://zhuanlan.zhihu.com/p/687928845" target="_blank">技术神秘化的去魅：Sora关键技术逆向工程图解</a> ）。而且，尽管目前有不少公开文献在用LLM+RL增强大模型的推理能力，但几乎找不到做Hidden COT生成的工作，所以可供直接参考的内容非常少，这为分析o1进一步增添了难度。</p><p>那是否就没办法了呢？倒也不一定，如果多观察细节，再加上一些专业性的推论，我觉得还是有痕迹可循的。本文以相对容易理解的方式来对o1做些技术原理分析，试图回答下列问题：</p><p>除了复杂逻辑推理能力获得极大增强，o1还有其它什么重要意义？</p><p>o1的完整训练过程大致会是怎样的？</p><p>o1是单个模型，还是多个模型？</p><p>O1中的RL状态空间如何定义？行为空间如何定义？会用何种Reward Model？可能用何种训练数据？LLM和RM融合后的模型结构可能会是怎样的？……等等</p><p>为行文中指称方便，我将文中推导的模型称为“Reverse-o1”。当然，里面有些部分有判断依据，有些则是根据主流技术作出的推断，只要OpenAI不官宣技术框架，大概一千个从业者能有一千种解法，我主要参考了AlphaZero的做法，试图在此基础上融合LLM和RL，很多看法比较主观，谨慎参考。</p><h2>OpenAI o1的重要意义</h2><p>我个人认为OpenAI o1是大模型技术领域的一个巨大突破，除了复杂逻辑推理能力获得极大提升外，这里展开分析下它在其它方面的意义和价值所在。</p><p><b>首先，o1给大模型带来了自我反思与错误修正能力，我觉得这点价值特别大。</b>GPT 4这类模型，因为在输出答案的时候是逐个Token输出，当输出长度较长的时候，中间某些Token出错是一定会发生的，但即使LLM后来知道前面输出的Token错了，它也得将错就错往下继续编（这也是大模型幻觉的来源之一，为了看上去逻辑合理，LLM得用100个错误来掩盖前面的第一个错误），因为落Token无悔，没有机制让它去修正前面的错误。</p><p>而o1在“思考”也就是生成Hidden COT的过程中，如果你分析过OpenAI官网给出的Hidden COT例子的话，会发现它确实能意识到之前犯错了，并能自动进行修正。这种自我错误识别与修正对于LLM能做长链条思考及解决复杂任务非常重要，相当于越过了一个锁住LLM能力的很高的门槛。</p><p><b>第二，所谓新型的RL的Scaling law</b>。OpenAI自己PR可能更强调这点，各种解读也比较看中这一点。我猜测o1的RL大概率要么用了相对复杂的、类似AlphaGo的MCTS树搜索，要么用了简单树结构拓展，比如生成多个候选，从中选择最好的（Best-of-N Sampling），这种策略如果连续用，其实也是一种简单的树搜索结构。也有可能两者一起用。不论怎样，树搜索结构大概率是用了，COT是线性的不假，但这是产出结果，不代表内部思考过程就一定是线性的，我觉得靠线性思维推导过程很难解决复杂问题，树形结构几乎是不可避免的。</p><p>有人问了，你有证据能说明o1大概率用了搜索树结构吗？我没有证据，但是可以推断，我的判断依据来自于o1 mini。之前的研究结论是这样的：尽管小模型语言能力强、世界知识还可以，但逻辑推理能力很难提起来，即使你通过比如蒸馏等措施试图把逻辑能力内化到小模型的参数里，效果有但有限，小模型和大模型差距最大的能力就是逻辑推理能力了。意思是说，纯靠参数内化来提升小模型的逻辑推理能力估计提升幅度有限。但o1 mini明显是个小模型，其复杂逻辑推理能力非常强，而且看样子可通过配置来提升或者降低它的逻辑推理能力（所谓inference-time Scaling law），如果你了解AlphaGo的运作机制的话，会发现这都是比较典型的搜索树的特点，可以通过控制搜索空间大小来提升模型能力。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-95aeaee70ceced5bad8b235ba56ef5b6_1440w.jpg" width="2422" /></figure><p>虽然我个人认为，如果把通过设置参数来控制如何拓展树结构（比如控制搜索的宽度和深度），这种模式如果能被称为Scaling law的话，多少有点勉强，若这样，那我们可以说2006年AlphaGo出来就有Scaling law了。</p><p>但不管怎么称呼它，无法忽视的是这种方法的可扩展性极好，无论是在RL训练阶段，还是LLM的Inference阶段，只要改下参数配置来增加树搜索的宽度和深度，就能通过增加算力提升效果，可扩展性好且方式灵活。从这点讲，o1确实具有重要意义，因为这证明了它把怎么融合LLM和树搜索这条路走通了，LLM模型能够达到AGI的上限就被提高了一大截。</p><p><b>第三，在o1之后，小模型大行其道真正成为可能。</b>小模型最近大半年也比较火，但从能力获取角度看，其实还是有上限锁定的，这个锁定小模型上限的就是逻辑推理能力。上面提到了，小模型的能力特点是：语言能力很强不比大模型弱、世界知识不如大模型但是可以通过给更多数据持续提升、受限于模型规模，逻辑推理能力能提升但比较困难。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pica.zhimg.com/v2-3c3cefb0f2f574642e42b420d891153c_1440w.jpg" width="2734" /></figure><p>所以小模型的优化重点是世界知识和逻辑推理能力，而从o1 mini的效果（世界知识弱、逻辑推理强）可推出，之后我们可以采用“能力分治”（DCA，Divide-and-Conquer of Ability）的模式推进小模型的技术发展（参考上图）：把语言、世界知识及逻辑推理三个能力解耦，语言能力靠小模型自身、逻辑推理靠类似o1的通过RL获得的深度思考能力，而世界知识可以靠外挂RAG获得增强。</p><p>通过“能力分治”，小模型完全可能具备目前最强大模型的能力，这等于真正为小模型扫清了前进路上的障碍，而SLM做起来成本又比较低，很多人和机构都可以做这事，所以可以预测：之后这种DCA模式将会大行其道，形成一种新的研发小模型的范式。</p><p><b>第四，o1可能会引发“安全对齐”新的范式。</b>O1在做安全对齐方面，大概采用了类似Anthropic的“AI宪法”的思路，就是说给定一些安全守则，指明哪些行为能做，哪些不能做，在o1逻辑推理能力提高之后，它遵循这些法则的能力也获得了极大增强，安全能力比GPT 4o强很多。这可能引发安全对齐新的模式：大家可以先把模型的逻辑推理能力加强，然后在此之上采取类似“AI宪法”的思路，因为OpenAI o1证明这种模式可极大增强大模型的安全能力。</p><p><b>第五，“强化学习+LLM”的领域泛化能力，可能不局限于理科领域。</b>强化学习适合解决Reward比较明确的复杂问题，典型的是数理化、Coding等有标准答案的学科，所以很多人会质疑o1是否能泛化到更宽的领域。确实，o1的思考能力能否泛化到没有明确标准答案、Reward不好量化的领域是它发展的关键，泛化得好，则打开阳光大道，泛化得不好，领域局限性就会比较强。</p><p>我推测OpenAI可能已经找到了一些非数理学科的Reward定义方法，并将这个方法通过RL拓展到更多领域。既然o1可以读懂并遵循安全规则，以 “AI宪法”的思路解决安全问题，我觉得由此可以推导出一种针对模糊标准的Reward赋予方法：就是说针对不好量化的领域，通过写一些文字类的判断标准或规则，让大模型读懂并遵循它，以此来作为是否给予Reward的标准，符合标准则Reward高，否则Reward低。例如，针对写作文，就可以列出好文章的标准（结构清晰、文笔优美等规则），让大模型据此来给Reward。如此就能拓展到很多领域。</p><p>当然，想要这么做可能要分步骤，先用好给Reward的数理问题增强模型的复杂推理能力到一定层级，这样它就能看懂规则了，然后再做那些不好量化Reward的领域。（这都是我的猜测，没有依据）</p><p>由上述分析可看出，o1这条技术方向不仅增强了模型的复杂逻辑能力，由此可能引发大模型研发很多重要方向的革新，这是为何我说o1重要的主要原因。</p><h2>OpenAI o1的完整训练过程推演</h2><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-9fb64105589b35f9a877702acf990746_1440w.jpg" width="2744" /></figure><p>GPT 4等LLM模型训练一般由“预训练”和“后训练”两个阶段组成（参考上图）。“预训练”通过Next Token Prediction来从海量数据吸收语言、世界知识、逻辑推理、代码等基础能力，模型规模越大、训练数据量越多，则模型能力越强，我们一般说的Scaling Law指的是这一阶段的模型扩展特性，也是LLM训练最消耗算力资源的地方。“后训练”则分为SFT、RM和PPO三个过程，统称为人工反馈的强化学习（RLHF），这一阶段的主要目的有两个，一个是让LLM能遵循指令来做各种任务，另一个是内容安全，不让LLM输出不礼貌的内容。而训练好的模型推理（Inference）过程则是对于用户的问题直接逐个生成Token来形成答案。</p><p>OpenAI o1的整个训练和推理过程应与GPT 4这类典型LLM有较大区别。<b>首先，“预训练”阶段应该是重新训练的，不太可能是在GPT 4o上通过继续预训练得到</b>。证据很好找，OpenAI官方一再宣称o1 mini逻辑推理能力极强，但在世界知识方面很弱。如果是在其它模型上魔改的，世界知识不会比GPT 4o mini更弱，所以侧面说明了是重新训练的；另外，这也说明了o1这类侧重逻辑推理的模型，在预训练阶段的数据配比方面，应该极大增加了逻辑类训练数据比如STEM数据、代码、论文等的比例，甚至我都怀疑o1 mini是否引入了通用数据都不好说，否则不需要老强调知识方面能力弱。</p><p>在“后训练”阶段，应该有一个环节是用来增强LLM模型的指令遵循能力的，也就是说<b>RLHF阶段应该是有的</b>。因为o1在遵循指令方面能力并不弱，而且生成的Hidden COT片段里明显也包含很多指令性的内容，如果遵循指令能力比较弱，估计对于生成Hidden COT也有负面影响。所以，推断起来这个环节大概在“思考”阶段之前。（但是RLHF阶段未必有RM和PPO）。但这里和GPT 4对应的RLHF阶段应有两个重要的不同：首先，o1应该在这个阶段没有做内容安全方面的事情，大概率是挪到后面的阶段了（也有可能这两阶段都做了？）。其次，这个阶段大概率也会极大增强逻辑推理类的指令遵循数据比例，以此进一步加强基座模型的逻辑推理能力，原因我们等会专门说明。</p><p>接下来的阶段，就是o1最大的特点，所谓<b>引入了“系统2”的慢思考能力</b>。ClosedAI只说用了RL强化学习，其它任何都没提，技术保密工作一流。由此，我们只能推断出o1融合了LLM和RL来实现模型“先想后说”的Think能力。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-17e2677569d4a2e673b87da785213a73_1440w.jpg" width="2334" /></figure><p><b>OpenAI o1应把“内容安全”相关的能力挪到了“Think”阶段之后，而且做法和GPT 4应该也有很大不同。</b>在o1通过Think阶段进一步增强了它的逻辑推理能力之后，并没有用与安全相关的Instruct数据去调整模型参数，而是转为在比如System Prompt里引入人写好的LLM应该遵循的若干安全规则，比如不能输出制造有害产品比如毒品的细节内容等等。O1逻辑能力增强后，在输出时基本能够参考“安全条例说明书”，不输出有害内容，这做法类似于之前Anthropic的“AI宪法”的思路(依据参考上图)。而且，o1在内容安全方面的能力比GPT 4o强很多，这意味着将来大模型安全范式的巨大变化：应该先极大增强模型的逻辑推理能力，继而采取类似“AI宪法”或者叫“AI安全说明书”的模式来做。很明显如果这样，安全这事情做起来就简单多了，因为等于把LLM当人看了，你告诉他哪些能做，哪些不能做，当它逻辑能力强起来，现在就完全能看懂了，就这么回事。</p><p>以上是o1的训练过程，在模型推理（Inference）阶段，o1体现出了“先思考再发言”的特点，分为三个阶段：首先通过思考，根据用户Prompt的问题生成能体现思考过程的Hidden COT数据，因为很多Hidden COT很长，于是引入了“COT摘要”阶段，从很长的Hidden COT里提取一些关键思考环节展示给用户看看，最后根据COT输出答案。</p><p>从上面内容可看出，o1无论在训练还是模型inference阶段，和传统的LLM应该还是有很大区别的。此外，我在这里再展开讲讲两个事情。</p><p>第一个，想要仿造模型来达到类似o1的效果，一个很容易想到的取巧的方式是：既不去专门增强基座模型的逻辑推理能力（比如大幅增加预训练中逻辑类数据占比），也不做“慢思考”阶段的RL训练（因为不知道怎么做的），只是侧重在模型inference阶段加入“Think”的过程，比如想办法引入最简单的Best-of-N Sampling这种树拓展策略，再写写Prompt提醒让LLM自己要自我思考、自我反思，两者相结合，也可以让模型自己写Hidden COT。这样做，也能一定程度上提升模型的推理效果。但是，这种做法效果提升的天花板比较低，就是说你模型逻辑推理能力看着提高了一些，然后就会被卡住，即使再增加inference阶段的算力（就是把采样数量N比如从10个拓展到50个，类似这种。Inference-time Scaling law大概其实很可能就是这个意思，您觉得这做法是law还是不law呢？）其实也没用。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-ad532ab3a436e71986f1e772b1b885de_1440w.jpg" width="2694" /></figure><p>这个结论来自于文献“Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters”及“Are More LM Calls All You Need? Towards the Scaling Properties of Compound AI Systems”，它们证明了：对于简单或者中等难度的逻辑推理问题，通过inference-time 增加算力，比如树搜索等方式，比去增强模型的“预训练”阶段的逻辑推理能力来得效果要明显；而对于高难度的逻辑推理问题，则只靠inference-time很难提升，有时还是负面作用，不如去增强模型“预训练”阶段的逻辑能力(参考上图)。</p><p>这是为啥呢？您可以想想，其实里面的道理细想一下很好理解。这是因为对于简单或中等难度的问题，模型在inference的时候很可能给出答案中的大部分步骤都是对的（或者多次采样中多数是对的），只有个别步骤错误，导致最终回答错误。通过比如Best-of-N Sampling这种简单树搜索方法来增加输出的多样性，再加上靠谱的Verifier筛一筛，是比较容易把这个小错误修正过来的。但对于高难度的逻辑问题，因为模型输出内容中大部分步骤可能都是错的（或者多次采样中大多数都是错的，这种情况你投个票采取多数人意见看看，结果估计很悲催），你想靠inference-time增加算力无力回天。</p><p>我自己也是根据上述思考，才进一步反推出上面讲的o1可能的训练过程的：OpenAI o1的基座模型，不论是Pre-training还是Post-training阶段，大概率极大增强了基座模型的复杂逻辑推理能力，这是它能在后续inference-time增加算力解决复杂问题的根基。</p><p>所以关于这个点的结论应该是这样的：只靠inference-time增加算力，仅对容易和中等难度的逻辑问题有用，想要不断提升模型的复杂推理能力，还需要继续在Pre-Train和Post-Training阶段下功夫。</p><p>讲到这有人就问了：那我也没钱自己训练基座模型啊？这可如何是好？这其实是绝大多数人面临的问题。其实拿来主义也应该可以，但是你得选那些逻辑推理能力强的基座模型，我估计代码类的基座模型相对比较适合，然后想办法在“Think”训练和“Think”inference方面做点工作，感觉应该也是可以的，而且对算力的需求也到不了大多数人做不了的程度。</p><p>第二个展开讲讲的事情。其实跟第一个有关，我看现在很多人看了o1后都说，Scaling范式变了，只要去Scale Inference-time的算力，模型推理效果就能一直Scaling。很明显这是进入误区了，原因上面讲了，如果只做Inference-time算力的拓展，模型效果天花板应该不会太高，归根结底还得去拓展Pre-train或者Post-train阶段模型的复杂逻辑推理能力，最起码两者是个相辅相成互相促进的作用，只谈inference-time Scaling大概率是不对的。</p><h2>o1应由多个模型构成</h2><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-e06726a685a277f46889bae988cae0ea_1440w.jpg" width="1664" /></figure><p>从o1的System Card可以明确看出，o1除了一个主模型外，至少还有一个相对独立的“Hidden COT摘要模型”(参考上图)，它的作用是根据用户输入问题及生成的Hidden COT，提供一份简洁且内容安全的COT摘要。所以，<b>o1至少由两个模型构成。</b></p><p>那么，问题是：<b>除了主模型和摘要模型，还有其它模型存在吗？我觉得大概率是有的</b>。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-b9073bba97390a15a6447f5f21e3019f_1440w.jpg" width="2706" /></figure><p>我们可以从o1的价格入手分析。目前已知：o1 Preview比GPT 4o的输入价格贵3倍，输出价格贵4倍，o1 mini输入和输出价格都是GPT 4o mini的20倍（参考上图）。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-c38d2e5cd2e9bf026fc13ab56bbdc0b3_1440w.jpg" width="1326" /></figure><p>这里插入一段，解释下为何大模型的输入价格和输出价格是不同的，这是因为在大模型推理（inference，相对模型训练来说的，不是指逻辑推理）阶段，分为Prefill和Decoding两个阶段(参考上图)。Prefill阶段首先把用户的输入prompt通过并行计算，产生每个Token 对应Self Attention的Key-Value，并存储在KV Cache中，供Decoding阶段产生每个Token时候计算Self Attention时候用，这个阶段每个Token的Key-Value可并行计算，模型运行一次能输出多个Token的KV，所以GPU利用率高；而Decoding阶段根据用户Prompt生成后续内容，但模型运行一次只能产生一个Token，所以无法有效利用GPU的并行计算特长，资源利用率不足。资源利用率的差异导致了输出阶段成本高，这是为何大模型一般输出价格是输入价格3到4倍的原因。</p><p>说回来，关于价格的核心问题是：为何比如o1 mini的输入价格（输入部分大模型的处理逻辑简单，只产生Prompt对应的KV Cache，更容易分析）是GPT 4o mini的20倍？这是个很奇怪的点，仔细思考的话，这里应包含关于o1内部机制的很多线索。输入价格对应Prefill阶段，Prefill原则上只处理用户输入Prompt和Sys Prompt。Prefill阶段价格贵20倍，只有两个可能：</p><p>一种可能是用户Prompt+Sys Prompt的输入长度是GPT 4o mini输入的20倍。用户输入的Prompt对o1和4o来说当然是一样的，如果增加这么多输入，只能是OpenAI往sys Prompt里塞入了很多东西。但是考虑到o1 Preview只比GPT 4o贵3倍，那么sys Prompt特别长的可能性就不大了，否则o1 Preview的输入价格也应该比GPT 4o贵20倍才是。另外，如果只是sys Prompt带来的价格上升，那么o1在Decoding阶段就不应该那么贵了，因为sys Prompt 主要影响Prefill阶段的计算成本（当然，如果KV Cache长了，Decoding在计算Self Attention的时候计算量也会增加，因为要看到更长的上文，但是以目前大模型对长文本的支持能力，成本不会高太多）。</p><p>所以，针对这种可能性，结论大概是：OpenAI可能往sys Prompt里塞入东西了（应该是上面提到的“安全规则手册”啥的），但是并没有达到20倍价格的差异。塞入很长的sys Prompt这条原因不能解释20倍价格差距。</p><p>我们来考虑第二种可能性。如果假设输入Prompt长度差异没有太大，那么从Prefill计算机制角度来看，只能理解为o1 mini的模型总参数量是GPT 4o mini的20倍左右（除了摘要模型外，还有十多倍的差异）。这里又有两种可能，一种是说o1 mini就一个模型，那么它参数量是GPT 4o的大约20倍，这个很明显不成立，我们可以看到各种测试中o1 mini跑的速度挺快的，所以单个模型不可能太大；</p><p>于是，剩下的唯一解释就只能是：o1 mini除了一个主模型，一个摘要模型外，大概还有18个规模相当的其它模型。考虑到o1 Preview输入价格只比GPT 4o贵三倍，可以理解为o1 Preview除了一个主模型，一个摘要模型，还有另外一个规模相当的其它模型。因为o1 Preview的总体工作机制应该和o1 mini是类似的，可知o1 Preview多出来的那一个模型，和o1 mini多出来的那18个模型（那为啥这18个模型不共享KV Cache呢？如果可以共享KV Cache的话，起码在Prefill阶段，18个模型可以缩减为1个模型，那么o1 mini的输入价格只需要比GPT 4o mini贵3倍就够了。既然仍然贵20倍，侧面说明了这18个模型本身模型参数或者配置是有差异的，导致相互之间无法共享KV Cache），大概是干同一类事情的。而这个事情的性质呢，是模型个数可伸缩配置的，就是说你可以设置这个地方是部署1个、5个还是18个这类模型，而且这类模型相互之间还有些差异导致无法共享KV Cache。O1 mini在很多场景的效果要比o1 Preview效果好，一定程度上可能是跟这类模型的部署个数有关的，所以我推断，这类模型大概率跟树搜索有关。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-acae36667fed19c7c092b7273c6f9d1a_1440w.jpg" width="2290" /></figure><p>综合起来，也就是说，<b>o1模型大概由三部分构成(参考上图)：一个主模型，一个摘要模型，还有一类可灵活配置个数的跟树搜索相关的模型池子</b>。如果我们自己想要给出技术方案逆向工程o1，你的技术方案可能就需要满足这个约束条件，需要包含这些模型，并能解释清楚这类模型池子的运作机制。</p><h2>OpenAI O1可能采用的训练数据</h2><h3>人工标注数据</h3><p> 首先，训练o1肯定会人工标注一批COT思考过程，就是说拿到一批&lt;问题，答案&gt;数据，通过人工把解决问题的思考过程和步骤写下来，形成&lt;问题，思考过程（包括思考过程中出现的错误及错误修正过程），答案&gt;。如果没有人工标注过程，那么COT里出现的:Hmm，wait，…这种，如果是纯靠LLM自己产生的，那估计LLM已经有意识了，这个概率很小，这些大概率最初来自于人工标注数据。可以用这些数据SFT一下o1初始的模型，启动模型的输出模式，让它熟悉这种表达方式，但是仅靠SFT肯定是不够的。</p><h3> 合成数据</h3><p>人工标注难度大、成本高，所以人工标注的COT数据数量不会太多，人工标注的问题是可扩展性太差，优点是质量比较高；之后可以采用合成数据的模式，一种最直观的合成数据的方式就类似上面提到制作PRM标注数据的模式：从人工标注的COT里面截取一段人工标注片段，然后使用MCTS树搜索方式去补齐后续推理过程，每个片段跑多次，有的最后答案正确有的错误，无论是正确还是错误，都可以作为合成数据来训练o1模型。如果更激进一些，对于有确定标准答案的逻辑问题，可以通过不断试错的模式直接从问题开始搜索正确答案，这里搜索到的正确答案和错误答案都可以用来训练o1模型（但是这貌似就已经是o1了？所以可能性不大）。</p><h3> 代码COT数据的反向生成</h3><p>有一种极大拓展代码COT数据的办法：我们有大量现成的各种代码，可以教会大模型试着从代码反向生成Hidden COT的推理步骤，这个应该是可行的，并能极大拓展Coding类型的COT数据。（类似的思路借鉴自：Planning In Natural Language Improves LLM Search For Code Generation）</p><h3>数学COT的反向生成</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-f28af3f85e4e00dd5766eba08a1e409c_1440w.jpg" width="2600" /></figure><p> AlphaProof这种能力强的数学解题系统，整体思路是首先把自然语言的数学问题通过一个模型转化为形式化语言描述，然后使用lean及类似AlphaZero的模式，通过强化学习和树搜索来不断搜索并验证中间推理步骤。这种方法效果是可以保证的，目前基本可达到IMO银牌选手水准（参考上图蓝色部分）。但是这种需要转化成形式化语言再解题的系统有一个问题，就是通用性差，基本只能用来解决数学题，很难扩展到其它领域。 </p><p><b>受到代码反向生成的启发，我觉得也可以反向生成数学COT</b>（参考上图红色部分）。既然AlphaProof可以构造从自然语言问题翻译成形式化数学语言的神经网络，那也可以构造一个反向生成的模型，就是把数学形式语言翻译成自然语言，然后用这个翻译系统把AlphaProof找到的解题推理过程，从形式化语言转换成自然语言思考COT。当然，中间做错的也可以用，因为它有明确的验证系统，每一步即使错了，为啥错也知道，这些也可以翻译成自然语言。这样可以构造出千万量级甚至上亿量级的数学推理COT思维过程数据。我觉得这个思路大体是可行的。</p><p>OpenAI o1目前在数学和Coding方面效果最好，可知这方面的训练数据是最多的，我不知道是否会采用类似反向生成的思路来自动构造COT数据，但貌似这种方法看上去可行性还比较高。</p><h2>Reverse-o1：RL的关键要素及如何将RL与LLM融合</h2><p>我们从这里开始推导o1可能以何种方式将RL与LLM融合起来，并把推导出的模型称为Reverse-o1。</p><p>我们会先分析下在Hidden COT场景下RL的关键要素：状态空间（State Space）、行为空间（Action Space）、奖励模型（Reward Model）。至于RL方法，我推测采用类似AlphaGo/AlphaZero的概率较大，有几个原因：</p><p>首先，据说OpenAI员工每天要读好几遍萨顿写的“苦涩的教训”，而里面提到“能够发挥算力的通用方法，如搜索和学习，将最终大获成功”，这里的搜索主要指的就是DeepMind AlphaGo的MCST方法，OpenAI员工耳濡目染不把搜索用起来做个实践也说不过去不是？</p><p>第二，前几天OpenAI官宣的o1主力成员采访视频里，有员工提到了他们一直以来都在尝试如何将AlphaGo的搜索方法和LLM融合起来，这也是证据之一。</p><p>所以，之后会简单介绍下AlphaZero的工作原理，并尝试将其和LLM融合起来构造复杂逻辑推理系统。</p><h3>O1中RL的状态空间：Token序列组成的连续状态空间</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-8675ae548e9a87c0b80601c5bcd416f7_1440w.jpg" width="2742" /></figure><p>关于o1的RL状态空间，首先的问题是：这个状态空间是离散的还是连续的？大概率是连续状态空间，或者说最好把它看成是连续状态空间。O1由LLM和RL组合而来，当用户输入问题时，很自然的，这些组成问题的Token序列作为一个整体可以看成第一个状态（State1），State1的Token序列作为o1模型的输入，o1在行为空间里选择某个行为（至于行为空间如何定义后面再谈），先不管这个行为是什么，反正选择这个行为后，o1会输出一个Token序列片段（不会是完整的Hidden COT，应该是其中的某个片段）。之后，o1把新生成的Hidden COT片段内容追加到State1之后，形成State2，再次作为o1的新输入，o1根据新输入选择新的行为，输出新的Token序列片段…..如此往复，直到Hidden COT输出结束。基本是这么个过程。</p><p>o1的RL状态空间不太可能由离散状态构成，你很难清晰地划分出若干具体状态。当然，可以说极端情况下，每个Token形成状态空间中的一个离散状态，但是这样基本没有实际的可行性。如果是每个Token代表一个状态S，首先这个状态组合空间太大。假设Token词典大小是10万，2个Token组合空间就是10万的平方，长度为n的Token序列，状态空间就是10万的n次方，基本是天文数字。其次，对于o1的RL来说，每输入一个Token就需要选择某个行为A，并生成下一个Token代表转移到另一个状态S’。如果RL过程带有搜索，意味着每个Token需要做一次搜索，而我们从很多o1的网上例子可以看到，很多时候Hidden COT是非常长的，几十上百K都有可能，这计算量基本是不可接受的。所以把每个Token看成离散状态，不是不行，但颗粒度太细，感觉很难在实际中应用。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://picx.zhimg.com/v2-4a1163dfae8d9fdf081994b0a3efb4e9_1440w.jpg" width="2740" /></figure><p>我觉得把o1的状态空间看成由Token序列组成的连续状态空间比较合适，上面例子尽管提到了State1或者State2，看着好像是离散状态，这只是方便解释过程而已（当然，如果把State1看成在巨大无比的Token组合空间中采样的一个点，这没问题）。就类似RL打游戏或者RL下围棋，RL输入的游戏（或围棋）画面由比如1024*1024个不同像素构成（不同像素可以类比为LLM的不同Token），由于像素组合空间过于巨大，很难清晰定义离散的一个一个State到底是什么，所以一般RL打游戏或者下围棋都是把输入图像当作一个整体，看成连续状态空间，通过一个神经网络来映射到某个具体的行为上。O1的状态空间和图像是类似的（参考上图），可以把一个Token片段类比RL打游戏对应的某个图片输入，看成由Token序列组成的连续状态空间，经过o1的LLM+RL神经网络映射到某个行为空间中的行为。</p><p>从上面分析可以看出，打游戏或者下围棋采用的RL技术，大都是以连续状态空间作为网络输入，而输出大都是离散行为空间中的某个行为，所以很明显这些地方采用的RL技术就比较适合用来作为o1的RL部分的解决方案，而采取离散状态空间的RL模型，比如MDP类方法就不太适合。</p><h3>O1中RL的可能行为空间：“思考因子（Thought-Factor）”离散行为空间</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-42ece6771834ba4ac3468a02f836c182_1440w.jpg" width="1914" /></figure><p>O1的RL技术方案，其中最关键的环节很有可能是如何定义行为（Action）空间。OpenAI 01的Hidden COT产生过程，本质上是在让机器模仿人在解决复杂问题产生的思考过程，而人在思考复杂问题时，有比较固定且数量并不太多的“思考模式”或者可以叫“思考因子”。比如拿到一个复杂问题，我们一般会首先明确这个问题的目标是什么，然后把复杂问题拆解成几个环节或者步骤，为了得到某一个具体步骤的解法，可能会提出一个假设，然后验证这个假设是否成立，如果不成立，那么继续提出新的假设，直到解决这个子问题…..我们也可能在过程中会进行验算并发现某些中间环节出现错误，并把错误修正过来。</p><p>如果仔细分析OpenAI官网放出来的几个Hidden COT，会发现是可以从里面归纳出一些典型的人类思考问题的一些隐含的“思考因子”的（参考上图，我给出了一些具体的例子）。我觉得要是把Hidden COT看成一个一个Token构成的，RL这事情就很难做了（Hidden COT的状态空间已经是连续非离散的，如果行为空间也是非离散的或者组合空间过大，RL很难建模。所以行为空间是离散的，这个极大概率为真，当然怎么定义离散的行为空间应有不同方法），在我的设想中，一个合理的方法是归纳出人类思考复杂问题的隐含的“思考因子”,以此作为候选的行为集合，比如：“拆解问题”、“复述目标”、“检查结果”、“修正错误”、“提出假设”等等，总体数量应该不会太多，即使划分得细致一些的话，估计也就几十到上百种。而针对每个具体的“思考因子”，可以产生符合对应分布概率的Token片段，比如行为若是“提出假设”因子，则生成“Alternatively”这个Token的概率就比较大（通过PPO从训练数据里学到的）。那么，Hidden COT片段很可能其真实面貌是长这样的：</p><p>&lt;ACT_Proposer-Start&gt; Alternatively, perhaps combine the numbers in some way. &lt;ACT_Proposer-End&gt;   (提出假设)</p><p>&lt;ACT_RephraseTarget-Start&gt; Overall Task:  Write a bash script that takes one argument (the string representing the matrix) and outputs its transpose in the same format.&lt;ACT_RephraseTarget-End&gt;   (复述目标)</p><p>也就是说，OpenAI的Hidden COT的原始内容或者训练数据，在形式上有可能是这样的二级结构：</p><p>&lt;Think_Start&gt;  （Hidden COT起始标记）</p><p>……</p><p>&lt;ACT-1_Start&gt;token token token…..&lt;ACT-1_End&gt;   （思考因子1）</p><p>&lt;ACT-2_Start&gt;token token token…..&lt;ACT-2_End&gt;   （思考因子2）</p><p>&lt;ACT-3_Start&gt;token token token…..&lt;ACT-3_End&gt;   （思考因子3） </p><p>……</p><p>&lt;ACT-n_Start&gt;token token token…..&lt;ACT-n_End&gt;    （思考因子n）</p><p>&lt;Think_End&gt;     （Hidden COT结束标记）</p><figure><img class="origin_image zh-lightbox-thumb" src="https://picx.zhimg.com/v2-da915a993a7eecb442e29cd11edd1c27_1440w.jpg" width="1846" /></figure><p>这种层级的Hidden COT结构，能体现出RL和LLM的优势结合，离散行为空间比如估算给定状态S采取何种行为，即函数Q(S,A)的估算，这是RL擅长做的事情，而思考因子标签中的Token生成则是LLM擅长的事情，LLM可以根据对应“思考因子”的类型，学习调整因子标签内部Token的生成概率。上图展示了如上所述二级“思考因子”离散行为空间后，o1的可能运作形式。在生成Hidden COT的过程中，输入和输出都带有ACT行为Token的起始和结束符号，首先，O1根据当前的问题和已经生成的Hidden COT片段，预测下一个最可能采取的“思考因子”，以决定后面要采取怎样的具体思考模式，然后在这个“思考因子”指导下，LLM生成具体的Token序列，以“思考因子”的结束Token作为这种思维模式的结束标记。并将本步输出的Token序列并入输入，来循环往复地生成下一步思考的对应行为及Token序列。(当然整个过程都是我的设想，没有具体证据)。</p><p>那您会问：为啥我在给出的Hidden COT例子里看不到“思考因子”对应的起始和结束Token呢？可能展示给用户的COT是过滤后的版本。你想，Hidden COT的起始和结束Token（&lt;Think_Start&gt;/&lt;Think_End&gt;），这两个Token极大概率是会有的，您不也没看到不是？说明输出的是过滤后的COT，那么，原先是有“思考因子”标记，但显示的时候被过滤掉，这也是有可能的。</p><h3>O1中RL模型的奖励模型（Reward Model）</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-56c22423a3318236e0ff14aabad6cb29_1440w.jpg" width="2238" /></figure><p>Reward如何设置对于RL来说至关重要，之前LLM+RL的学术工作其实蛮多的，归纳一下的话，目前常用的Reward模型有两种（参考上图）：结果奖励模型（ORM，Output Reward Model）和过程奖励模型（PRM，Process Reward Model ）。</p><p>ORM的意思是训练一个模型，不管推导过程有多少步，只对最后结果打分。如果对照Hidden COT看的话，意思是只有o1把Hidden COT完整地写完了，ORM才给出一个奖励信号，模型结果若和标准答案对上了，给奖励1，如果答案错误，给奖励-1，类似这种。很明显，ORM的优点是反馈信号准确，比如对于数学题，模型要么做对了，要么做错了，很明确，所以反馈信号就精准；但ORM的缺点是反馈稀疏，意思就是反馈信号少，这个很直观，哪怕你推导过程写10页纸，反正最后只有一个反馈信号。（OpenAI 训练大模型时RLHF阶段的RM模型，就属于ORM）</p><p>PRM的含义是训练一个模型，能对中间每个过程都给予反馈信号，这样在推导过程中错在哪个步骤就很清楚，不用等到最后，所以它的特点是反馈信号丰富不稀疏。但问题来了，要训练PRM就需要有每一步有标注的数据，这么多标注信号怎么来？常规做法是靠人工标注，比如去年很火的OpenAI的PRM工作“Let’s Verify Step by Step”，就是靠人工标注了80万中间步骤反馈信号的数学题推导过程，而且证明了PRM效果要比ORM好。所以，PRM的优点是反馈多效果好，但是训练数据制作成本太高，一般人做不了。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-974a44bd62e5cfc9c90e8e222c4b67a8_1440w.jpg" width="2866" /></figure><p>那有没有相对成本低的方法来做给每一步做标注呢？有。我目前看到比较好的做法是这么做的（参考上图）：假设我们手上有一批有完整推导过程的数学题，可以先把第一个解题步骤抄过来，然后用MCTS树靠搜索的方式去继续往后推导，可以从这个步骤出发做多次推导，其中有些推导过程会得到正确答案，有的结果错误，原则上从这个步骤出发的多次推导中，通向正确答案比例越高，说明抄过来的这步推导过程对于得到正确答案比较重要，则可以标注一个高分，然后可以抄过来第二个解题步骤，依此处理…..这样就能自动给每个推导步骤做质量标注。然后用这种数据去训练PRM模型，PRM就能给每个推理步骤打分。但很明显，通过这种数据训练出来的PRM打分的精准性肯定比不上ORM。</p><p><b>那么OpenAI o1在训练过程会采用ORM还是PRM呢？我估计两者都会用。ORM精准，PRM反馈丰富，两者各有优点，结合起来效果应会更好。</b>另外，o1的官网提到了“Our large-scale reinforcement learning algorithm teaches the model how to think productively using its chain of thought in a highly data-efficient training process.”，这里的“data-efficient”，应该指的就是PRM。</p><h3>AlphaZero的基本原理</h3><p> 这里会首先介绍下AlphaZero的基本工作原理，我们后面给出的Reverse-o1方案，核心是如何将RL和LLM融合起来，大框架主要参照AlphaZero的主体思路，所以这里做些说明以方便后续内容的理解。</p><p>2017年年底AlphaGo的棋类游戏通用版本Alpha Zero问世，不仅围棋，对于国际象棋、日本将棋等其他棋类游戏，AlphaZero也以压倒性优势战胜包括AlphaGo在内的最强的AI程序。   </p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-5e38775f5c3c0a7dcf6c2898a7113ff4_1440w.jpg" width="797" /></figure><p>AlphaZero从技术手段上和AlphaGo相比并未有本质上的改进，主体仍然是MCTS蒙特卡洛搜索树加神经网络的结构以及RL训练方法，但是技术实现上简单优雅很多（参考上图）。主要改动包含两处：一处是将AlphaGo的两个预测网络（策略网络P和价值网络V，策略网络P主要用于预测在当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 下，执行每个行为 <img alt="a" src="https://www.zhihu.com/equation?tex=a" /> 也就是可能的落子位置的胜率，即函数 <img alt="P(S,a)" src="https://www.zhihu.com/equation?tex=P%28S%2Ca%29" /> ；而价值网络V主要评估当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 最终能够赢棋的整体概率，即函数 <img alt="V(S)" src="https://www.zhihu.com/equation?tex=V%28S%29" /> ，是一个在比如0到1之间的数值， <img alt="V(S)" src="https://www.zhihu.com/equation?tex=V%28S%29" /> 数值越大，从当前局面 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 出发赢棋概率越高。）合并成一个网络，同时产生两类输出 <img alt="P(S,a)" src="https://www.zhihu.com/equation?tex=P%28S%2Ca%29" /> 和 <img alt="V(S)" src="https://www.zhihu.com/equation?tex=V%28S%29" /> ；第二处是网络结构从CNN结构升级为ResNet。AlphaZero完全放弃了从人类棋局来进行下棋经验的学习，直接从一张白纸开始通过自我对弈的方式进行学习，并仅仅通过三天的Self Play便获得了远超人类千年积累的围棋经验。  </p><p>AlphaZero结合了MCTS和RL，MCTS是主体，RL起到了加速搜索速度的作用。在Self Play过程中（参考上图a），对于某个AI棋手，它会用MCTS搜索，对当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 下各个可能落子（Action）都去搜一下，每个位置经过搜索之后，能获得每个落子位置赢棋的概率分布 <img alt="\pi" src="https://www.zhihu.com/equation?tex=%5Cpi" /> ，从中选择概率最大的位置来落子，之后另一个AI棋手也采用类似的思路去落子……这么一来一回直到分出胜负（ <img alt="z" src="https://www.zhihu.com/equation?tex=z" /> 指出谁是胜者,Reward信号）。  </p><p>到目前为止，貌似我们还没看到神经网络结构的作用，其实它主要是在MCTS搜索某个落子位置的时候发挥作用。因为从某个落子位置出发开始搜索，可搜索空间实在太大，靠暴力搜索肯定行不通，所以策略网络 <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> 和价值网络 <img alt="V" src="https://www.zhihu.com/equation?tex=V" /> （AlphaZero已经融合为一个网络了，分开说主要是为了方便阐述）的作用主要是引导搜索过程，优先搜索赢面大的路径，剪枝掉赢面小的路径，这样来增加搜索效率。</p><p>在搜索过程中神经网络参数固定不动，当一盘棋下完最终分出胜负，知道胜者后，可针对下棋路径上经过的每个状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 产生对应的训练数据。对于策略网络 <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> 来说，学习目标是MCST搜索获得的当时状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 出发落子概率分布 <img alt="\pi" src="https://www.zhihu.com/equation?tex=%5Cpi" /> ，而对于价值网络 <img alt="V" src="https://www.zhihu.com/equation?tex=V" /> 来说，学习目标则是“最后的胜者 <img alt="z" src="https://www.zhihu.com/equation?tex=z" /> 获胜概率大”这一事实。然后根据这些训练数据就可以调整神经网络参数，这样它在下一局对弈过程中能力会更强（可以看出AlphaZero的奖励模型是ORM）。这样通过无限重复的对弈过程，AlphaZero能力就越来越强。</p><p>应该意识到：对于AlphaZero来说，其本质其实还是MCTS蒙特卡洛树搜索。围棋之所以看着难度大难以克服，主要是搜索空间实在太大，单纯靠暴力搜索完全不可行。如果我们假设现在有个机器无限强大，能够快速遍历所有搜索空间，那么其实单纯使用MCST树搜索，不依靠RL，机器也能达到完美的博弈状态。AlphaGo Zero通过自我对弈以及深度增强学习主要达到了能够更好地评估棋盘状态( <img alt="V" src="https://www.zhihu.com/equation?tex=V" /> )和落子质量( <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> )，优先选择走那些赢面大的博弈路径，这样能够舍弃大量的劣质路径，从而极大减少了需要搜索的空间，自我进化主要体现在评估棋面状态（ <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> 和 <img alt="V" src="https://www.zhihu.com/equation?tex=V" /> ）越来越准，所以能越来越快地找到赢面最大的落子位置。而之所以能够通过自我对弈产生大量训练数据，是因为下棋是个规则定义很清晰的任务，到了一定状态就能够赢或者输，无非这种最终的赢或者输来得晚一些，不是每一步落子就能看到的。 </p><h3>LLM与RL融合后的Reverse-o1模型网络结构</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pica.zhimg.com/v2-43db16e22bb757833665c241c6c54946_1440w.jpg" width="2470" /></figure><p>o1和下棋不同的一点是：除了RL，即使是Hidden COT，在背后也是靠一个Token一个Token输出的，LLM一定还是其中的主体结构，但RL肯定也需要一个网络结构去调整模型参数，来逐步学会内部的思考过程。所以，我们首先面临的问题是：<b>如何融合LLM和RL两个模型，来获得一个同时混合LLM和RL两者功能的完整网络结构</b>。</p><p>上图给出了一个我设想中的结构：主体仍然是基于Transformer的LLM模型（Dense或MOE都可以，mini版本应是Dense结构），当输入“问题+已经生成的部分Hidden COT”（也就是由连续Token序列组成的当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> ）之后，经GPT网络对当前状态进行编码。在LLM 输出Head之上，可分化出两个子结构：一个用于常规的LLM 预测Next Token，这与通常的LLM一致；在Head之上，可以搭建RL模型结构，这里参考了AlphaZero的思路，一个网络两个输出。比如可以用FFN网络结构，一方面输出策略网络 <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> 结果（ <img alt="P(S,a)" src="https://www.zhihu.com/equation?tex=P%28S%2Ca%29" /> ），代表在当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 下，下一步Action“思考因子”的分布概率 <img alt="\pi" src="https://www.zhihu.com/equation?tex=%5Cpi" /> ，某个“思考因子”概率越大，则下一步这个Action被选中执行可能性越大；另外一方面会输出价值网络V结果（ <img alt="V(S)" src="https://www.zhihu.com/equation?tex=V%28S%29" /> ），代表当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 通向最终正确答案的概率大小，概率越大说明当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 质量越高，意味着目前已输出的这部分Hidden COT整体质量较高。</p><p>到了这一步，当Hidden COT处于某个状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 的时候，经过网络可知下一步应该采取什么动作，也获得了当前状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 通向成功答案的概率。但目前仍缺少一部分内容，即在已知下一步“思考因子”行为后，对应的Hidden COT 一系列输出的Tokens。</p><p> 一种简单的方法是用LLM head之上的LLM部分持续输出后续Tokens(有人工数据训练的时候，可以用PPO来增加对应Token的输出概率)，在输出后续Token的时候并不考虑RL的输出，直到LLM输出到 <img alt="&lt;{Act_i}-End&gt;" src="https://www.zhihu.com/equation?tex=%3C%7BAct_i%7D-End%3E" /> 之后，再去判断RL的输出选择动作…..持续此过程，结合LLM和RL输出Hidden COT的模型就能运转起来。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-2672062a4f732da8188fc618e7acf4a6_1440w.jpg" width="2860" /></figure><p>前文我们分析过，o1大概率会使用过程奖励模型PRM，还有，它可能是由多个模型构成的。在这两个约束条件下，可以如此改造上面的模型结构（参考上图）：在已知下一步“思考因子”后，不由主模型来生成后续Tokens，为了增加后续生成COT的质量，可采用Best-of-N Sampling的思路，由多个复制的Reverse-o1模型（不同副本可以设置不同的温度参数，增加输出的多样性）各自给出一个Token序列，然后由离线训练好的PRM作为评委打分，选择得分最高的Token序列，作为本次“思考因子”后续的输出Tokens。选出最佳内容后，可同步给主模型，主模型执行一次类似Prefill的操作，即可同步输出最佳内容，然后开始下一轮的输出……可如此办理，这么做明显生成的Token序列质量会更高。</p><h3>MCTS树搜索下的Reverse-o1</h3><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-64aaba6a01f83cf8a7ef58dc15e3c927_1440w.jpg" width="2766" /></figure><p>我们仿照AlphaZero，引入主体结构MCTS，它的运行流程如下（参考上图）：当用户输入问题后，Reverse-o1使用MCTS树，对于每个可能的“思考因子”进行搜索，在搜索时会用策略网络 <img alt="P" src="https://www.zhihu.com/equation?tex=P" /> 和价值网络 <img alt="V" src="https://www.zhihu.com/equation?tex=V" /> 来快速寻找最优搜索路径，这样得到所有“思考因子”的概率分布pai，概率数值越大则代表采取这类思考通向正确答案概率越高。之后选择概率最大的“思考因子”作为当前状态下的行为，并如上节内容所述，由Reverse-o1生成针对这个行为下的COT Tokens片段。将COT Tokens片段并入用户问题，形成新的状态……依次往后走，直到产生问题的答案，和标准答案对比后，要么对要么错，由此得到对应的Output Reward。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-f5906db6b6866eae8ec98992cc4f4d43_1440w.jpg" width="2610" /></figure><p>仿照AlphaZero，从状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 出发，搜索某个“思考因子”指向正确答案的概率时，以 <img alt="max(Q+U)" src="https://www.zhihu.com/equation?tex=max%28Q%2BU%29" /> 的方式寻找最优下一状态 <img alt="S'" src="https://www.zhihu.com/equation?tex=S%27" /> ，而 <img alt="Q" src="https://www.zhihu.com/equation?tex=Q" /> 函数与价值网络 <img alt="V(S)" src="https://www.zhihu.com/equation?tex=V%28S%29" /> 正相关， <img alt="U" src="https://www.zhihu.com/equation?tex=U" /> 函数与策略网络 <img alt="P(S,A)" src="https://www.zhihu.com/equation?tex=P%28S%2CA%29" /> 正相关，所以 <img alt="max(Q+U)" src="https://www.zhihu.com/equation?tex=max%28Q%2BU%29" /> 的含义是通过价值网络和策略网络的指引，来寻找高质量的搜索路径；当搜索到叶结点的时候，会进行节点扩展，并用策略网络和价值网络估算初始化相关搜索参数，之后由低向上更新最优路径上所有状态对应的 <img alt="Q" src="https://www.zhihu.com/equation?tex=Q" /> 函数。当每个候选的“思考因子”经过一轮搜索后会得到所有行为的分布概率 <img alt="\pi" src="https://www.zhihu.com/equation?tex=%5Cpi" /> ，完成搜索步骤。O1搜索时与下棋不同的地方在于：如果要往下一状态转移，还需要根据当前选到的行为，产生对应的Hidden COT tokens，这个步骤可由上文讲述的Best-of-N Sampling策略来完成。</p><p>当从问题开始，逐步生成Hidden COT片段后，走到答案阶段，会获得Output Reward，完成一次通过中间环节到答案的MCTS搜索过程。如果答案正确，可设置Reward=1，答案错误可设置Reward=-1，在此基础上针对走到答案所经过的所有中间状态 <img alt="S" src="https://www.zhihu.com/equation?tex=S" /> 构造训练数据，来训练策略网络P和价值网络V，策略网络的学习目标是对应状态MCTS搜索到的行为概率分布 <img alt="\pi" src="https://www.zhihu.com/equation?tex=%5Cpi" /> ，价值网络的学习目标是Output Reward。</p><p>除此外，对于搜索过程每个被选中“思考因子”通过Best-of-N Sampling得到的对应Hidden COT tokens序列（也可以拿到PRM赋予这个tokens序列对应的Process Reward分数），则可以利用PPO（PRM的Reward作为PPO的Reward）来调整LLM模型参数，使得LLM之后在遇到这个“思考因子”后，提高这些Tokens的生成概率。</p><p>到目前为止，差不多可以结束o1的整个逆向工程之旅了，前文提到的一些约束条件（o1应该由多个模型构成、应该用了某种或者某几种树搜索、RPM和ORM应该都会用等）在设想中的Reverse-o1中基本都得到了体现。</p><p>但是，我个人觉得还有一个问题值得深入思考：“思考因子”是必须存在的吗？毕竟这需要靠人工去归纳人类的潜在思维模式，仍然有比较强的人工痕迹存在，而且会增加人工标注数据的成本。这个问题我确实思考了好几天，结论貌似是：整个框架还可以是这个框架，不用引入“思考因子”或者把“思考因子”改为“隐式思考因子（Hidden Thought Factor）”应该也是可以的，因文章已经太长，解释起来有点复杂，这里先略过。</p>
<br /><br />
来源：知乎 www.zhihu.com<br />
    
作者：<a href="http://www.zhihu.com/people/zhang-jun-lin-76?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=author">张俊林</a><br />
            
<br />
【知乎日报】千万用户的选择，做朋友圈里的新鲜事分享大牛。
        <a href="http://daily.zhihu.com?utm_source=rssyanwenzi&amp;utm_campaign=tuijian&amp;utm_medium=rssnormal" target="_blank">点击下载</a><br />
        </div>
        <div class="article-link">
            <a href="/article/d776a5ecc6ec11683813bb23cda98f8f.html">阅读全文</a>
            <a href="http://zhuanlan.zhihu.com/p/721952915?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/256e62a16636f322eb89a56ae6d46571.html">精灵宝可梦（Pokémon）中有哪些有趣的冷（小）知识？</a></h3>
        <div class="article-meta">
            <span class="category">知识</span>
            <span class="date">Wed, 15 Jan 2025 12:06:18 +0800</span>
        </div>
        <div class="article-summary">
            <p>长文预警！多图预警！流量炸弹！</p><p>宝可梦系列在争议声中来到的第八世代，我也将对这个已经有了好几年的回答进行新一轮更新。随着条目越来越多，为了提高文章质量，此次将会精简一部分内容，贴合题目中的“冷”和“有趣”。</p><p>以下内容涉及主系列游戏、官方旁支作品、TV动画、都市传说、周边产品、八卦吐槽等。</p><p>———————————————————————</p><p>1、看起来很像水属性的露力丽其实是一般属性的，在第六世代追加妖精属性以前，露力丽是除伊布外唯一进化后单属性改变的宝可梦。</p><p><img src="https://pic1.zhimg.com/e259d4b31899e7dfc14df93540ac9dbd_720w.jpg?source=b1748391?rss" /></p><p>2、若将同一种宝可梦的不同形态视作一条进化路线，则无畏小子是除伊布外唯一有超过两条进化线路的，同时它的加入使前代无家族关系的两种宝可梦（快拳郎和飞腿郎）变成了同一家族。</p><p><img src="https://picx.zhimg.com/0bd30e93049f596e5ee13c543fceee3c_720w.jpg?source=b1748391?rss" /></p><p>3、独特进化方式1：在土居忍士进化时，若主角包包中有精灵球，则会在进化成铁面忍者的同时分裂出脱壳忍者，唯一的一变二。</p><p>4、独特进化方式2：丑丑鱼有两种进化方式变成美纳斯，除了达到美丽度要求并升级这种方式外，由于第五世代没有华丽大赛，于是追加了携带美丽鳞片通讯交换的进化方式。</p><p>5、独特进化方式3：盖盖虫和小嘴蜗通讯交换后分别进化，可以看出设计思路是小嘴蜗把它的硬壳送给了盖盖虫。</p><p><img src="https://picx.zhimg.com/7c41bfd5207ad86b96b8ce50f52eddef_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pica.zhimg.com/5c8fdb4e6449ab04a2b8a80d34adfd93_720w.jpg?source=b1748391?rss" /></p><p>6、独特进化方式4：好啦鱿进化时需要把3DS倒过来（内置陀螺仪控制），这个家族的形象、招式等都是围绕着“颠倒”这个主题设计的。</p><p><img src="https://pic1.zhimg.com/a7ec557e32d8f0ad9e6f1e3a877379ae_720w.jpg?source=b1748391?rss" /></p><p>7、独特进化方式5：小球飞鱼在队伍中有铁炮鱼时升级进化，虽然在游戏中两者并不会真的合体，但是它们设定上是共生关系。</p><p><img src="https://picx.zhimg.com/649d99d6683d086c9f0c56480d8a42d0_720w.jpg?source=b1748391?rss" /></p><p>8、独特进化方式6：小仙奶需要通过操控主角原地旋转来进化成霜奶仙，在时间段、旋转方向、旋转持续时间、所携带糖饰不同的情形下，所得到的霜奶仙颜色、形态也是不同的。</p><p>9、飞天螳螂是唯一进化后种族值总和不变的宝可梦。顺便一提，飞天螳螂有性别差异，雄性和雌性的腹部大小不一样。</p><p><img src="https://pic1.zhimg.com/0ed3dec70abcec97d047707650e6d229_720w.jpg?source=b1748391?rss" /></p><p>10、鬼斯通身高1.6m，进化后降低为1.5m，不过游戏里看起来好像耿鬼才大只一点(O_O)</p><p><img src="https://picx.zhimg.com/a513a893a055efc41656acda07329f3e_720w.jpg?source=b1748391?rss" /></p><p>11、类似地，虽然臭臭泥看起来比较大坨，但它和臭泥一样都是30kg。</p><p><img src="https://pic1.zhimg.com/8760653dca0fc6982a76b824651a299e_720w.jpg?source=b1748391?rss" /></p><p>12、考虑特性，麻麻鳗鱼王家族没有弱点，因为唯一的弱点地面属性被其飘浮特性所消除。在第六世代以前，勾魂眼和花岩怪也没有弱点，幽灵+恶属性不被妖精属性外的其他属性克制。</p><p><img src="https://picx.zhimg.com/bdebabd7ef8a24c3842ad6931b883d19_720w.jpg?source=b1748391?rss" /></p><p>13、在第一世代，超能力属性和幽灵属性的克制关系和现在的相反，当时幽灵对超能力无效，而现在幽灵对超能力克制。（不过第一世代幽灵属性的招式极少，这个克制关系在当时并没有什么存在感。）</p><p><img src="https://picx.zhimg.com/4436f96b7c57e6d8197631640bd741d7_720w.jpg?source=b1748391?rss" /></p><p>14、梦幻、几何雪花、小陨星和破破舵轮无性别，但却能学会迷人。当然这并没有什么用……</p><p>15、飞行单属性的宝可梦非常稀罕，只有龙卷云及携带对应道具的阿尔宙斯和银伴战兽，以及八代新加入的稚山雀和蓝鸦。</p><p><img src="https://pic1.zhimg.com/9634acea811a21b8e6fb140014f4d5c0_720w.jpg?source=b1748391?rss" /></p><p>16、在第一世代只有一个龙属性招式，那就是固定伤害40的龙之怒。</p><p>17、水属性拥有最多种类的宝可梦，一般属性拥有最多种类的招式。</p><p>18、森林诅咒和万圣夜两个招式可以实现三属性，进而能够出现八倍克制。例如虫+钢属性的巨钳螳螂，被森林诅咒追加第三属性草，则会被火属性八倍克制。</p><p><img src="https://picx.zhimg.com/7216dcc30d6b9eff2b9868daa1e81317_720w.jpg?source=b1748391?rss" /></p><p>19、飞身重压是目前唯一的双属性招式。在计算克制关系时会分别计算格斗和飞行属性的克制关系，再将它们相乘。</p><p>20、能学会跃起这个神技的不只有鲤鱼王，还有丑丑鱼、毽子草、露力丽和跳跳猪等。虽然这个招式最初设计目的仅仅是为了体现鲤鱼王的弱小，然而网络对战中也出现了利用此招式高PP的特点，耗光对手PP而迫使其使用挣扎的娱乐性战术。</p><p><img src="https://picx.zhimg.com/91952cd9a70b1b6d7bc5b9f384b1c28d_720w.jpg?source=b1748391?rss" /></p><p>21、虽然地鼠没有手臂但却能学会需要有手臂的抓、劈开、居合斩等招式⊙▽⊙</p><p><img src="https://pic1.zhimg.com/ccae89b6b0ad5aea32fb9e0b35b510ad_720w.jpg?source=b1748391?rss" /></p><p>22、特性互换这个招式的作用是交换双方的特性，当年民间直译为“特性交换”。然后，因为贴吧论坛等平台和谐系统的作用中间那两个字经常显示不出来…于是被玩家称为“敏感词”。</p><p>23、众所周知冰属性招式打水属性是一半伤害，然而第六世代加入了特殊的冷冻干燥招式。这个招式对水属性强制两倍伤害，即使有输电、一般皮肤效果或在反转对战中也是强制两倍伤害。</p><p>24、第五世代动画中等离子队即将首次登场时，日本发生了特大海啸灾害，由于相关剧集中有城市被破坏的情节而被紧急修改播放计划，以至于之后的剧情全都被打乱重做，所有很多人吐槽五代动画剧情烂是有原因的。</p><p>25、谁是弱点最多的宝可梦？以下PM都有7个弱点：草+超能力的蛋蛋、椰蛋树、时拉比（飞毒虫鬼火冰恶），岩石+恶的班基拉斯（格地虫钢水草仙），草+恶的长鼻叶、狡猾天狗、梦歌仙人掌（格飞毒虫火冰仙），草+冰的雪笠怪、暴雪王（格飞毒岩虫钢火），岩石+格斗的代拉基翁（格地钢水草超仙）。另外，如果失去飘浮特性，岩石+超能力的太阳岩和月石也会有7个弱点。</p><p><img src="https://picx.zhimg.com/aa8b25f0d51aaf6ba216650f3b7112e4_720w.jpg?source=b1748391?rss" /></p><p>26、烈空坐的气闸特性能使天气的影响消失，因此成为了盖欧卡和固拉多战斗的调停者形象。而实际上可达鸭的无关天气特性也有相同的效果，其日文ノーテンキ与“乐天”以及“no 天气”同音。</p><p><img src="https://picx.zhimg.com/c303e067411527a89b8ce63e79ff97db_720w.jpg?source=b1748391?rss" /></p><p>27、在满努力满个体的情形下，大力士或瑜珈之力特性宝可梦的折合攻击种族值约等于原攻击种族值乘以2加50。也就是说玛力露丽的实际物攻种族值是150，恰雷姆是170，超级恰雷姆是250，超级大嘴娃是爆表的260。</p><p><img src="https://pica.zhimg.com/cf87aa62b92060fe0d91130499d44e6c_720w.jpg?source=b1748391?rss" /></p><p>28、用于回忆招式的心之鳞片是爱心鱼的鳞片。关都地区没有爱心鱼，在火红叶绿版中用于回忆招式的是大蘑菇和小蘑菇。</p><p>29、破破舵轮的原型是船锚，但它并不是钢属性。这是因为它的本体是海草。</p><p>30、花舞鸟通过使用花蜜改变形态，四种形态对应四种属性，但其实都不能学会对应属性的攻击招式。</p><p><img src="https://pic1.zhimg.com/v2-3d4a84e8946fd53f1707c541fdf5fb70_720w.jpg?source=b1748391?rss" /></p><p>31、三合一磁怪的体重是小磁怪的十倍，而不是三倍。</p><p>32、快龙的头上有一个不太起眼的角，在第一世代，它甚至可以学会一击必杀招式角钻。话说我玩了十年才发现它有角……</p><p><img src="https://picx.zhimg.com/57f3b8fe2035452c8a9654a9c1763fdb_720w.jpg?source=b1748391?rss" /></p><p>33、吼鲸王长14.5米，体重只有398kg，粗略计算密度，会发现甚至比空气的密度还小。</p><p>34、看起来娇小的幼基拉斯重达72 kg，动画中曾发生与之有关的错误。（当然如果智爷的设定是麒麟臂的话那就不是错误了←_←）</p><p><img src="https://picx.zhimg.com/99f7ecd1b25ee112fa885b2b00904507_720w.jpg?source=b1748391?rss" /></p><p>35、在第一二世代迷唇姐的脸是黑色的，而现在是深紫色的，原因是之前的形象和名字被认为涉嫌种族歧视。顺便一提迷唇姐不像沙奈朵那样有女装大佬，而是只有雌性。</p><p><img src="https://picx.zhimg.com/350f10b490a0e7c755198f401ecc044f_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/6dacad66efb0821e62280fe60dd5f800_720w.jpg?source=b1748391?rss" /></p><p>36、叉字蝠较小的那对翅膀是后肢演化来的，看起来像小爪子的部位其实是尾巴。</p><p><img src="https://pica.zhimg.com/8ba96c149a2f5e44b6b22f068613850a_720w.jpg?source=b1748391?rss" /></p><p>37、晃晃斑的花纹是由性格值决定的，理论上晃晃斑有数十亿种不同花纹，遇见两只花纹完全相同的晃晃斑几乎是不可能的。</p><p>38、雌性皮卡丘的尾巴末端是心形的，所以不要再问小智的皮卡丘是公是母了。</p><p><img src="https://pica.zhimg.com/46310e332a0c7d7278e3ceda2f0a38b6_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/82d83d320069ab47ab9bc43c5846e125_720w.jpg?source=b1748391?rss" /></p><p>39、现实中的青蛙多是绿色的，而以青蛙为原型宝可梦除蚊香蛙皇外竟然都是蓝色的……另外，蚊香蛙皇的旧译“牛蛙君”中的“君”并不是表示敬称，而是“君主”之意。</p><p><img src="https://picx.zhimg.com/d6e3f058fc42e734c2460069cb670331_720w.jpg?source=b1748391?rss" /></p><p>40、蚊香蝌蚪的“蚊香”，设计原型是现实中的蝌蚪因为腹部皮肤很薄，常常能从外部看到里面的盘卷的肠道。蚊香蝌蚪和蚊香君肚子上的花纹方向是相反的，而且蚊香泳士的花纹方向和蚊香君一致，蚊香蛙皇的花纹方向又和蚊香蝌蚪一致。</p><p><img src="https://picx.zhimg.com/ef32e5551d421b741894bfd5721cf955_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/4f4962b8cdb9bcf257bfe8f2954c0655_720w.jpg?source=b1748391?rss" /></p><p>41、观察一下铁甲蛹、摩鲁蛾、毛球和巴大蝶的脸，会发现铁甲蛹和摩鲁蛾长得像，毛球和巴大蝶长得像，仿佛进化关系弄反了一样。</p><p><img src="https://picx.zhimg.com/87dae6871b3fd25ab292dea554fe4755_720w.jpg?source=b1748391?rss" /></p><p>42、官方称，豪力和怪力的“内裤”并不是内裤，而是花纹……</p><p><img src="https://picx.zhimg.com/v2-83e8af4a6e3b16f5e95b153d773977c2_720w.jpg?source=b1748391?rss" /></p><p>43、豪力嘴里有尖牙，怪力却没有牙。</p><p><img src="https://picx.zhimg.com/0120333c0138a7bcd1839e6ed8c89430_720w.jpg?source=b1748391?rss" /></p><p>44、尼多兰和尼多后头上都有角，而作为中间形态的尼多娜却没有角。</p><p><img src="https://picx.zhimg.com/5d4b06b5287591744cfffc830df66905_720w.jpg?source=b1748391?rss" /></p><p>45、尼多家族中的多数成员其闪光形态是异性的普通颜色，例如闪光尼多朗是蓝色而闪光尼多兰是紫色，唯一例外的是闪光尼多后是绿色的。也许是有意设定，亦有可能是配色疏忽。</p><p><img src="https://picx.zhimg.com/8944c496fb8e8dd8377303e6a558bc2e_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/2777bd6d0313876d176c5a7efa7197af_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pica.zhimg.com/2391941c906998308417177d0578b727_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pic1.zhimg.com/0c213bc6af43fee69bb5dfb6bce80be3_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pic1.zhimg.com/264434d820a8274a60929476530a3669_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pic1.zhimg.com/34bf83e1e5173beeb8e585ac5a332771_720w.jpg?source=b1748391?rss" /></p><p>46、第四世代宝可梦结草儿，根据最后一次战斗的环境不同会变换为草木蓑衣、砂土蓑衣或垃圾蓑衣形态，但是三种形态都是虫单属性，进化以后才是双属性。</p><p><img src="https://picx.zhimg.com/cb8acb1e414f51822ad8036a56064992_720w.jpg?source=b1748391?rss" /></p><p>47、秃鹰丫头和秃鹰娜穿在身上的骨头可以组成一个完整的头骨。</p><p><img src="https://pic1.zhimg.com/6c9c26911966defc82c482d71b8b784a_720w.jpg?source=b1748391?rss" /></p><p>48、阿柏蛇圆形的头部、无毒牙的特点像是无毒蛇，银版的图鉴甚至直接点明它是无毒蛇。然而它依然是毒系，能学会毒系技能，尾巴的造型也基于有毒的响尾蛇。</p><p><img src="https://picx.zhimg.com/da589f34a65608ec47d4fbffffc042f6_720w.jpg?source=b1748391?rss" /></p><p>49、其实佐仓千代是一位派拉斯训练家（误）。</p><p><img src="https://pic1.zhimg.com/b4a5ede7ab32cc72e461b51cd08d01ef_720w.jpg?source=b1748391?rss" /></p><p>50、我曾长期以为哎呀球菇长着个萌萌的猪鼻子，后来仔细一看发现那是嘴。</p><p><img src="https://picx.zhimg.com/72cab3dcdeb54c9595437429c110d1f1_720w.jpg?source=b1748391?rss" /></p><p>51、信使鸟手里抓着的“口袋”是它的尾巴。</p><p><img src="https://pica.zhimg.com/v2-8652e219297a6eee1846d2022955dc47_720w.jpg?source=b1748391?rss" /></p><p>52、童偶熊的臀部有一张标签，因为它的原型是玩偶。</p><p><img src="https://picx.zhimg.com/v2-75313e75f917db6c6734781c8db3784f_720w.jpg?source=b1748391?rss" /></p><p>53、咕妞妞的耳朵是头顶的两个小孔，形似兔耳的结构是用来保护耳朵的耳罩，这也是其特性隔音的来源。</p><p><img src="https://pic1.zhimg.com/v2-2db8d3c4093a662af310832231f7dba5_720w.jpg?source=b1748391?rss" /></p><p>54、怖思壶是有真货假货之分的，真货只能通过野生捕获。它们通常情况下看不出差别，但在极巨化后，真货的壶底会有一个小标签。</p><p><img src="https://picx.zhimg.com/v2-c353f58c754adb0bf469b87a78599796_720w.jpg?source=b1748391?rss" /></p><p><br /></p><p><img src="https://pic1.zhimg.com/v2-7e1db8724551589219b87bd1abf7ef6a_720w.jpg?source=b1748391?rss" /></p><p>55、第六世代以前性别是由性格值决定的，三分之一的雌性露力丽进化后会变成公的。因为露力丽的性别比是1：3而玛丽露的性别比是1：1，这使得对于露力丽是雌性的性格值对于玛丽露可能是雄性。</p><p>56、除了印度象杀手雷丘，图鉴提到鬼斯的毒气也能放倒印度象。然而，鬼斯并不能学会毒瓦斯，没有手的它反而能学会火焰拳、冰冻拳和雷电拳。</p><p>57、虽然外表看起来像人类，但沙奈朵家族在第八世代以前不是人形群而是不定形群——这意味着能和它啪出后代的都是些臭泥鬼斯之流……第八世代中官方终于意识到这个槽点，给沙奈朵家族追加了人形群。</p><p><img src="https://picx.zhimg.com/6880b065e154bf36bc01e01f769bef35_720w.jpg?source=b1748391?rss" /></p><p>58、尼多朗和尼多兰是同一种宝可梦的性别差异，但由于第一世代没有性别系统，只好给予不同的编号，而日文和英文名字都是用雌雄符号区分的，如ニドラン♂和ニドラン♀。</p><p>59、只有雌性三蜜蜂可以进化成蜂女王，类似的还有夜盗火蜥。为了使蜂女王更稀有，三蜜蜂的性别比例设定为了7：1，但现实中的蜜蜂则是雌性数量远大于雄性。刷三蜜蜂的蛋党最怕什么——出公的6V闪。</p><p><img src="https://pic1.zhimg.com/86a291f0c120a2b5d2861be6018d97e1_720w.jpg?source=b1748391?rss" /></p><p>60、在第二世代，壶壶的壳里可以发酵出饮品，但之后的世代中这个功能被删除了，可能是为了防止不小心失去较稀有的树果。</p><p>61、图鉴上说呆壳兽尾巴上的大舌贝掉了以后会变回呆呆兽，但在游戏中做不到，事实上关于呆呆兽进化的设定在主系列游戏中都没有体现。</p><p>62、“大葱鸭，尖嘴鸭神奇宝贝，因为和特定的植物一起吃的话，味道极为鲜美，因此数量变得极少，是珍贵的神奇宝贝。”——来自动画EP048小智的图鉴。</p><p><img src="https://pic1.zhimg.com/c6f95cd383772eabb8ea807b71ba00f5_720w.jpg?source=b1748391?rss" /></p><p>63、派拉斯特的本体不是底下螃蟹一样的虫子，而是那个大蘑菇。由于图鉴的描述爱好者们普遍认同派拉斯特的行动由蘑菇主导，而虫体部分是被控制的活体还是尸体则有争议。</p><p><img src="https://picx.zhimg.com/2f3341c62adf957ca5dc16f08a54c4be_720w.jpg?source=b1748391?rss" /></p><p>64、虽然仙子伊布的形象很女性化但性别比却是7：1。形象带性别特征但有公有母的还有沙奈朵，长耳兔，怪力，哥德小姐，西狮海壬等。</p><p><img src="https://picx.zhimg.com/6af23d6f9e5e1ddf7acd115bd4a2b3e9_720w.jpg?source=b1748391?rss" /></p><p>65、臭臭花嘴里流出的“口水”其实是花蜜，图鉴的说法是闻着臭吃着香←_←</p><p><img src="https://pica.zhimg.com/f1bd10a818c4e417397be016c7e41dd7_720w.jpg?source=b1748391?rss" /></p><p>66、土龙“弟弟”有雌性，哥德“小姐”有雄性。而只有雌性的秃鹰丫头曾被译为秃鹰“小子”。</p><p><img src="https://picx.zhimg.com/26238b7e4f54fe68dd978187cd046244_720w.jpg?source=b1748391?rss" /></p><p>67、说到土龙弟弟，第六世代的Z神基格尔德因为属性是地面和龙属性被称为“土龙”，进而又被称为“土龙哥哥”。</p><p><img src="https://picx.zhimg.com/e2adc30cd07249251afcec47617794de_720w.jpg?source=b1748391?rss" /></p><p>68、早期游戏，尤其是第一二世代中的宝可梦，其图鉴资料中常常充斥着各种浮夸的设定，以下是一些初代PM的例子：大比鸟“以二马赫的速度飞行”，“视力超群，就算在1000米的高空也可以发现鲤鱼王的踪影”；雷丘“会发出十万伏特的电流，如果随便去触摸它，就连印度象也会被电死”；皮可西“张开耳朵时，连一公里外针掉下来的声音都可以听得一清二楚”；三地鼠是“擅长合作的3只地鼠的合体，也曾挖地到地下100公里引发大地震”；风速狗“一昼夜能跑10000千米的身影使得不少人为之陶醉”；蚊香泳士“用全身肌肉有力地游泳，奥林匹克选手也要甘拜下风”；胡地“有着比超级计算机计算速度还快的大脑。智商大约有5000”；腕力“有着可以扔飞100个大人的力量”；豪力“就算是力士的身体也只需要一根手指头就能轻松举起”；怪力“用发达的4只手在2秒内可以出拳1000发”；烈焰马“用和新干线一样的速度赶超它”；三合一磁怪“发射神秘的电波，半径1公里内温度会提高2度”；巨钳蟹“钳子中隐藏着一万马力的超级力量”；飞腿郎“腿的内侧变得像钻石一样硬”；快拳郎“拳速比新干线还快”；钻角犀兽“能在2000摄氏度的岩浆里生存”；快龙“绕地球一周仅需约16小时”。</p><p>69、猫鼬斩和饭匙蛇设定上是千年死对头，在第六世代的群聚对战中，他们会在攻击玩家前相互攻击。而胸前的花纹显示二者攻受分明……并且，因为都是陆上群，所以可以生蛋……</p><p><img src="https://picx.zhimg.com/f6aa3baa0d1aa66116c172a2443d1d3b_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pica.zhimg.com/9528f81d585be0a8f0d0c7ab1eccb6d4_720w.jpg?source=b1748391?rss" /></p><p>70、虽然标题叫信长的野望，但武将的形象都来自战国无双3。</p><p><img src="https://picx.zhimg.com/4ea248ec8f4a5ef43e3664ee6b78238d_720w.jpg?source=b1748391?rss" /></p><p>71、屠龙小能手的早期设计……</p><p><img src="https://picx.zhimg.com/d5f277b06912789968376e8dd9389ec8_720w.jpg?source=b1748391?rss" /></p><p>72、按官方的设定是先有了霹雳电球这样像精灵球的宝可梦，然后才有了精灵球。</p><p><img src="https://picx.zhimg.com/821831f5536c07844be7670cbc8be0d2_720w.jpg?source=b1748391?rss" /></p><p>73、滴蛛的原型是水蛛，而溜溜糖球的原型是水黾。</p><p><img src="https://pica.zhimg.com/v2-5cfb0a54162ccde7de99dd79759bfe6a_720w.jpg?source=b1748391?rss" /></p><p>74、多数非神兽宝可梦的初始亲密度为70。卷卷耳的初始亲密度为0，并且是唯一能通过升级学会迁怒的宝可梦；而它的进化型长耳兔的初始亲密度为140，并且是唯一能通过升级学会报恩的宝可梦。</p><p><img src="https://picx.zhimg.com/v2-a74511f69936b6533c8b4558b75513f4_720w.jpg?source=b1748391?rss" /></p><p>75、作为究极异兽，毒贝比家族非常特殊。1、是唯一有进化链的究极异兽；2、绝大多数数究极异兽的每一项种族值都是质数，而四颚针龙的速度种族值是121，不是质数。另外四颚针龙的腹部形状很像毒贝比的头部。</p><p><img src="https://pic1.zhimg.com/v2-cbf319f767840eb0837fead5e0439846_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/v2-7a010a0bcd5247c21ff5709cedfa3a70_720w.jpg?source=b1748391?rss" /></p><p>76、这些宝可梦名称中用的是“喵”：喵喵，向尾喵，魅力喵，东施喵，妙喵，超能妙喵，火斑喵，炎热喵；而这些宝可梦用的却是“猫”：优雅猫，小猫怪，勒克猫，伦琴猫，扒手猫。喵猫傻傻分不清。</p><p>77、官方统一中文翻译后，绝大多数宝可梦简繁版本的名称是字字对应的，例外的是火暴兽，简体写作“火暴兽”，繁体写作“火爆獸”。“暴”和“爆”并非简繁对应关系。</p><p>78、百变怪和蚊香蝌蚪的叫声相同，独角犀牛和喷火龙的叫声相同。</p><p>79、第一个被设计出来的宝可梦是钻角犀兽，内部编号001。</p><p><img src="https://pic1.zhimg.com/e40590a6384fefa38c4ff7e9350c2395_720w.jpg?source=b1748391?rss" /></p><p>80、麒麟奇的日文和英文都是回文，分别是キリンリキ和Girafarig。</p><p>81、除神兽和MAGA外种族值总和最高的是请假王，达670，其次就是鱼群形态的弱丁鱼和各个准神了。虽然请假王懒洋洋的，但它的速度种族值是100，超过了快龙的80和风速狗的95。</p><p><img src="https://picx.zhimg.com/425a3a9e6e4378b3b86909039b445ab7_720w.jpg?source=b1748391?rss" /></p><p>82、考虑到各国的宗教和文化差异，历代游戏，尤其是涉及神道文化较多的金银心魂，许多训练家贴图日本版和海外版不同，一个典型的例子是喇叭芽之塔中的和尚。</p><p><img src="https://pica.zhimg.com/2f53495955b956eceba0f7b880bda840_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/81a6d4b68ce9d1088cb57e3dd1b6cbfe_720w.jpg?source=b1748391?rss" /></p><p>83、动画中小刚是睁开过眼睛的。</p><p><img src="https://pica.zhimg.com/4a9bd1ecfe0f5b8202d888b26865db25_720w.jpg?source=b1748391?rss" /></p><p>84、从第二世代开始，伊布的新进化方式都体现了新作中加入的新元素：昼夜和好感度、区域升级进化、友谊系统。另外，若同时达到多种进化条件，其判定优先级是叶伊布/冰伊布&gt;仙子伊布&gt;太阳伊布/月亮伊布。</p><p><img src="https://pic1.zhimg.com/18e7e08b0705088984822580bf87600d_720w.jpg?source=b1748391?rss" /></p><p>85、在遥远的第一世代，10号道路的一个NPC提到她想要一种粉色的有花朵图案的宝可梦，这与第五世代的食梦梦相符。有说法称食梦梦在早期就被设计了出来但因不明原因成为废案，也有可能是官方填坑。</p><p><img src="https://picx.zhimg.com/9164876b66481795f638d8816a182fcf_720w.jpg?source=b1748391?rss" /></p><p>86、虽然鲤鱼王被设定为最弱宝可梦，但它的种族值总和并不是最低的，更低的还有拉鲁拉丝、刺尾虫、露力丽和向日种子等。第七世代的弱丁鱼创造了新低：175。</p><p><img src="https://picx.zhimg.com/229d6585c6cf84b9f4cda80bede8622e_720w.jpg?source=b1748391?rss" /></p><p>87、铁炮鱼和章鱼桶被视为进化前后差异最大的宝可梦，也是少有的能学习火属性技能的水属性宝可梦。巧合的是章鱼桶的日文写法和常见燃料辛烷相同。</p><p><img src="https://picx.zhimg.com/bb5c4bcb06f6e29c74003ea5b1e442c9_720w.jpg?source=b1748391?rss" /></p><p>88、花岩怪由108个魂魄组成，体重108kg，神奥编号108，双防种族值108。这和《水浒传》里的108好汉一样是取自某些佛教典故，花岩怪也因此被玩家戏称为好汉宝可梦。</p><p>89、绿宝石里的纯真正太满充和他的雄性沙奈朵被玩家戏称为绿色伪娘二人组。不过在复刻版中，他的沙奈朵换成了艾路雷朵。</p><p><img src="https://pic1.zhimg.com/9074740b6724017dc7c80f51aac3ef72_720w.jpg?source=b1748391?rss" /></p><p>90、宝石复刻版中为了体现丰缘地区的炎热气候，许多馆主的着装设计从长袖变成了短袖。</p><p><img src="https://pica.zhimg.com/48ece33cca5d93e4d6ab1d83dd161079_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pic1.zhimg.com/86864aa79a2a072a1a068c5f232670ab_720w.jpg?source=b1748391?rss" /></p><p>91、波克比加入动画的最初目的是为了遮挡小霞的露脐装以通过欧美国家的动画审查。当时金银版游戏还没有发售，也就是说波克比在动画中先于游戏出现。</p><p><img src="https://pic1.zhimg.com/a44283ab5db25ef3c737ac3c576d7fcb_720w.jpg?source=b1748391?rss" /></p><p>92、在日本真的可以找到宝可梦中心，是贩售宝可梦周边产品的商店，北到北海道南到冲绳都有，美国也有两家分店。</p><p><img src="https://pic1.zhimg.com/fd0ab3b4fdf901321bec4303dbd7fe06_720w.jpg?source=b1748391?rss" /></p><p>93、2014年世界杯的时候老任曾放出皮卡丘等宝可梦身着日本队球衣为日本队加油的宣传画。然而后来日本队战绩不佳，被网友吐槽“因为皮卡丘从来不进球”←_←传说日本队小组赛被淘汰后他们的主题薯片跌到了5日元一袋……</p><p><img src="https://picx.zhimg.com/d574d1dd815f1ad136f312fd8136d2e5_720w.jpg?source=b1748391?rss" /></p><p>94、都市传说：鬼斯通吃了皮可西后进化成耿鬼，只有0.1kg的鬼斯通进化后体重增加了约40kg，身高体重都与皮可西相近≥﹏≤</p><p><img src="https://picx.zhimg.com/75b2625ddfebfeee2e6375b51851adc0_720w.jpg?source=b1748391?rss" /></p><p><img src="https://pic1.zhimg.com/89f10f49d613ddb6693532fc47122932_720w.jpg?source=b1748391?rss" /></p><p>95、官方一直刻意回避地鼠在地面以下的部分：意念移动和自由落体对地鼠无效，在第五世代中出场时是从地下钻出来的，专业版图鉴也看不到地下的部分，于是关于这件事情有诸多都市传说和恶搞作品。</p><p><img src="https://pica.zhimg.com/e41161b9458b5e300413496c04f8497d_720w.jpg?source=b1748391?rss" /></p><p>96、大舌贝和鬼斯的样子有相似之处，并且在全国编号中两个家族相连，加之第五世代加入了招式破壳，于是涌现出一大波大舌贝五段进化的恶搞作品。</p><p><img src="https://picx.zhimg.com/619cfd6b77335acec1ded8469a95ac61_720w.jpg?source=b1748391?rss" /></p><p><img src="https://picx.zhimg.com/633ee7922d278620353d3360ff75d1ac_720w.jpg?source=b1748391?rss" /></p><p>97、虽然呆呆王看起来更高大上，但其实它的种族值总和与呆壳兽一样是490，区别只是防御与特防交换了过来。有可能在开发早期呆呆王曾被设定为呆壳兽的进化型，但后来又修改了。</p><p>98、紫苑镇怪谈基本已确定是谣言，而多边兽事件则是确有其事。当年让很多儿童进了医院的多边兽从此从动画中被和谐掉了。话说对那种视觉冲击的敏感度因人而异，答主的同学看了以后觉得要吐了，而答主本人表示看了没什么感觉@_@</p><p><img src="https://picx.zhimg.com/1b41e3f5668423e61833b83c0669b666_720w.jpg?source=b1748391?rss" /></p><p>99、08年剧场版播出时在官方网络投票中发生了有名的小磁怪事件，即当时官方发起活动要选出电影中最受玩家喜欢的三只宝可梦，承诺制作它们的主题壁纸。结果活动中有网友提出“小磁怪票数好少好可怜啊”，引发大量网友跟风式地给小磁怪投票，最后眼看着小磁怪就要超过电影的两个主角了，官方暗箱操作提前结束活动才得以收场，并从此再未进行过这样的网络投票。</p><p><img src="https://picx.zhimg.com/v2-883aa27c0efe26a186de7ff1cd780215_720w.jpg?source=b1748391?rss" /></p><p>100、宝可梦世界里也是有星座的，但与现实中的星座不同，他们的星座都是些“风妖精座”、“爆炸头水牛座”什么的←_←</p><p><img src="https://picx.zhimg.com/8cb9158c4917f757ea25ffbf424f0c42_720w.jpg?source=b1748391?rss" /></p><p>101、事实上“精灵宝可梦”这个翻译至少在2011年就有了，当时PM系列剧场版曾试图以该译名引进大陆但不知为何中途作罢了。而到了第七世代，这个曾经无人知晓的翻译成为了华语圈统一的官方翻译。</p><p>102、柯南里的圆谷光彦、海贼王里的乔巴、火影里的猿飞木叶丸、LOL里的提莫队长……都是皮卡丘配的音。</p><p><img src="https://pica.zhimg.com/2c6ef297b94174bea5748e83f687d73d_720w.jpg?source=b1748391?rss" /></p><p>103、动画第四季开始加入了宝可梦世界的专属文字，标志着其世界观与现实世界彻底分家。然而以罗马字母为原型的未知图腾就成为了无法改变的设计“污点”。</p><p><img src="https://picx.zhimg.com/v2-241d4ff111dd97342bef6eeee02b88d5_720w.jpg?source=b1748391?rss" /></p><p>104、黑白篇动画显示宝可梦世界也有扫二维码。</p><p><img src="https://picx.zhimg.com/ea87ff7108ba5e7ef74046e1c84af082_720w.jpg?source=b1748391?rss" /></p><p>105、每个博士的研究方向都不一样。初代大木博士研究PM和人类的关系，所以第一世代总强调训练师要爱PM什么的；金银空木博士研究繁殖，所以一开始叫主角去拿蛋；宝石小田卷博士研究生栖地，所以经常在野外被野生PM追；珍钻山梨博士研究进化，还提出90%的PM与进化有关；黑白红豆杉博士研究PM的起源，我也不知道她研究出了个啥，貌似黑白的含义是阴阳生一切；XY普拉塔洛博士研究超进化，第六世代的卖点。</p><p>106、始祖大鸟是唯一种族值总和与全国编号相同的宝可梦。</p><p><img src="https://pic1.zhimg.com/9ce523c5475c6bc409ddc803bbf39d4a_720w.jpg?source=b1748391?rss" /></p><p>107、也许皮神真的很稀有，动画中上一次出现野生皮卡丘是1998年的事情。</p><p><img src="https://picx.zhimg.com/d621e53223dfe2166fdd5a6c032d5d45_720w.jpg?source=b1748391?rss" /></p><p>108、心魂版中桔梗市和圆朱市的宝可梦中心是褐色的，与其古典风格相融合。而现实中圆朱市的原型京都市也因要与古建筑群相适应，全城的麦当劳招牌都是褐色的。</p><p>109、以游戏为原型的特别篇漫画很忠实地还原了第一二世代的宝可梦中心。</p><p><img src="https://picx.zhimg.com/739b0ccbb2778068585e39d0aec64b9d_720w.jpg?source=b1748391?rss" /></p><p>110、第一二世代的友好商店墙上有招牌，日版的写的是SHOP，美版的写的是MART。</p><p>111、超梦的设计灵感来源于20世纪末人们对克隆技术的恐慌，而就在1996年2月27日红绿版发售后半年不到，1996年7月5日，克隆羊多利诞生。</p><p><img src="https://picx.zhimg.com/9cd1421f8bd70d559ad20f543b5c6402_720w.jpg?source=b1748391?rss" /></p><p>112、满金道馆内的盆栽摆成了皮皮的图案，不过现在皮皮已经不是一般属性了。</p><p><img src="https://picx.zhimg.com/63e1a91e0bb2672cba5547c698591dc7_720w.jpg?source=b1748391?rss" /></p><p>113、勇基拉的原型，魔术师尤里·盖勒曾状告老任称勇基拉折弯汤匙的形象侵犯了其名誉权，但法院驳回了他的起诉。另外，勇基拉变胡地是少有的进化后体重减轻的情况。</p><p><img src="https://picx.zhimg.com/adc104ac312800ee200e99ad893709da_720w.jpg?source=b1748391?rss" /></p><p>114、洛奇亚和诺基亚的共同点在于防御力惊人←_←</p><p><img src="https://picx.zhimg.com/072dd9e32f499afb2e0478461e91082e_720w.jpg?source=b1748391?rss" /></p><p>115、传说武藏换个发型会很漂亮……</p><p><img src="https://picx.zhimg.com/v2-a13c2d592349084a9d1952caa85df04b_720w.jpg?source=b1748391?rss" /></p><p>116、小次郎除了败露球菇外的草属性宝可梦都会在从球里放出来时攻击他。</p><p><img src="https://picx.zhimg.com/6b6cb47aa15d6d37ba368a7d0319c24b_720w.jpg?source=b1748391?rss" /></p><p>117、话说，答主我曾把素利拍看成“素利柏”长达七八年……现在素利拍有了正式译名——引梦貘人，不用担心分不清拍和柏了。</p><p><img src="https://pic1.zhimg.com/b1ea48beb838f765d9978332ffa40d2c_720w.jpg?source=b1748391?rss" /></p><p>118、不考虑获得全国图鉴后发生的变化以及和前代联动等特殊功能，分布最广的宝可梦是超音蝠、可达鸭和小磁怪，从关都到阿罗拉从未缺席。但很不幸，它们仨都没拿到伽勒尔的签证……不过刚才得到情报，它们在剑盾DLC里又拿到了补签……真有你们的啊游戏富力克。</p><p>119、莉莉艾和XY里的瑟妹情敌米茹菲是同一声优配音——真是官方恶意←_←</p><p><img src="https://picx.zhimg.com/v2-0ca2b831fb246e6f2f803bbd67c1dc97_720w.jpg?source=b1748391?rss" /></p><p>120、理论上第一个正式向中国大陆发售的宝可梦游戏是iOS平台的宝可消消乐。不过，官方后来又认定2019年登陆国服的宝可梦探险寻宝才是第一个进入大陆的宝可梦游戏。</p><p><img src="https://pica.zhimg.com/v2-b03520ac64d6d2081d8380cc7d968747_720w.jpg?source=b1748391?rss" /></p><p>121、《宝可梦钓鱼大会》是一个神奇的存在——在2005年提供短期下载的一个NDS平台小游戏。该游戏数据缓存在NDS中，只要关机就会自动销毁，现在这款小游戏已经绝版。</p><p><img src="https://pic1.zhimg.com/v2-7ec2e9130941f7f33e4637d4ccb86496_720w.jpg?source=b1748391?rss" /></p><p>122、“梦球鬼剑”可以说是宝可梦世界锦标赛史上最著名的丑闻。当时取得过三届冠军的Ray选手使用了一只梦境球的坚盾剑怪，彼时梦境球是第五世代限定的，来自第六世代的坚盾剑怪不可能使用梦境球，因此这只坚盾剑怪必然是魔法产物，一时舆论哗然。不过在被连黑了五年后，第八世代重新解禁了梦境球，梦球鬼剑成为可能，坚盾剑怪终于摆脱了这个梗(ノ˃̩̩Δ˂̩̩ )ノ</p><p>123、然而新梗很快又找上了它……我们知道，从第六世代开始许多旧世代的宝可梦在种族值上得到了加强，例如巴大蝶的特攻种族值提高了10等等，以平衡新旧pm的能力。悲惨的是，坚盾剑怪在第八世代中，刀剑形态的双攻各削了10，盾牌形态的双防各削了10，成为迄今为止唯一种族值被削的宝可梦，史称剑盾削剑盾(*゜Д゜)</p><p>124、一般属性给人以这样的刻板印象：当一只宝可梦没有什么明显的属性特色时，就会被设定为一般属性，因而多为单属性。但实际上截止目前，一般已经和其他17种属性中的11种组合过了，以下各举一例。</p><p>+火：火炎狮</p><p>+水：大尾狸</p><p>+电：光电伞蜥</p><p>+草：四季鹿</p><p>+格斗：穿着熊</p><p>+地面：掘地兔</p><p>+飞行：大比鸟</p><p>+超能力：麒麟奇</p><p>+龙：老翁龙</p><p>+恶：堵拦熊</p><p>+妖精：胖丁</p><p>另外在黑白2宝可梦好莱坞的电影《忘不掉的记忆》中，机器人F-00是一般+钢属性。</p><p>125、乍看之下稚山雀有着犀利的眼神，但实际上其头部的白色半圆形不是眼白而是花纹，也就是说稚山雀长的是红色豆豆眼。</p><p><img src="https://pica.zhimg.com/v2-6224deaeddf1084727112ed0d67cf0fb_720w.jpg?source=b1748391?rss" /></p><p><br /></p><p><img src="https://pic1.zhimg.com/v2-68d4294bbd880005b9ec631ddddb4331_720w.jpg?source=b1748391?rss" /></p><p>126、绿毛虫、刺尾虫和雪吞虫的分类是“虫宝宝宝可梦”。</p><p><img src="https://pic1.zhimg.com/v2-78a80a75a9efe2ede7099d6fd659bf6a_720w.jpg?source=b1748391?rss" /></p><p>127、众所周知宝可梦无论长得多巨大都不超过一吨……不过，原本650kg的大王铜像由于重金属特性体重可以超过一吨。</p><p><img src="https://pic1.zhimg.com/v2-06c154c6c222f9bbf0c09671046736c7_720w.jpg?source=b1748391?rss" /></p><p>128、在《宝可梦大师》的日文版中，文案不小心把小茜和大奶罐的介绍混在了一起。于是玩家们看到小茜的介绍栏里赫然写着</p><p>“开朗健谈的满金道馆馆主。</p><p>每天产出20升奶。</p><p>产出的奶浓郁又美味。”</p><p><img src="https://picx.zhimg.com/v2-c9f45e31a2dda74cf846a533d25d8cc8_720w.jpg?source=b1748391?rss" /></p><p>129、话说日月初期莉莉艾喜欢宝可梦却不敢触摸的毛病，在现实中是真的有，因为我就是这样的…即使觉得小猫很可爱却不敢摸它，家里养了个仓鼠摸它要戴手套…但我仅限小型哺乳动物不敢摸，曾在动物园里肆无忌惮地撸老虎…</p><p>———————————————————————</p><p>如果觉得这篇文章不错，或者可怜答主我手打这么多字，就点个赞吧^ω^</p>
<br /><br />
来源：知乎 www.zhihu.com<br />
    
作者：<a href="http://www.zhihu.com/people/yang-tian-yu-53?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=author">Tinyu Young</a><br />
            
<br />
【知乎日报】千万用户的选择，做朋友圈里的新鲜事分享大牛。
        <a href="http://daily.zhihu.com?utm_source=rssyanwenzi&amp;utm_campaign=tuijian&amp;utm_medium=rssnormal" target="_blank">点击下载</a><br />
<br />
此问题还有 <a href="http://www.zhihu.com/question/38535302/answer/77262295?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">76 个回答，查看全部。</a><br />
                延伸阅读：<br />
<a href="http://www.zhihu.com/question/36223307?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">精灵宝可梦（Pokémon）里有哪些有趣的梗？</a><br />
            
<a href="http://www.zhihu.com/question/21028574?utm_campaign=rss&amp;utm_medium=rss&amp;utm_source=rss&amp;utm_content=title" target="_blank">宝可梦(Pokémon) 能吃吗？</a><br />
        </div>
        <div class="article-link">
            <a href="/article/256e62a16636f322eb89a56ae6d46571.html">阅读全文</a>
            <a href="http://www.zhihu.com/question/38535302/answer/77262295?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/1a026ee028c8d65cbd3208556f2d9109.html">理想 i8 的两张图，让理想汽车涨了 260 亿</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Tue, 25 Feb 2025 13:24:14 +0000</span>
        </div>
        <div class="article-summary">
            理想做好了一切准备。<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615597">原文链接</a> ·
<a href="https://www.ifanr.com/1615597#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/1a026ee028c8d65cbd3208556f2d9109.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615597?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/58c6ee58f9a5a12d2f55eb3ae327303e.html">AR 眼镜，正在迎来它的 iPhone 时刻</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Tue, 25 Feb 2025 11:52:28 +0000</span>
        </div>
        <div class="article-summary">
            从生不逢时，到生逢其时。<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615566">原文链接</a> ·
<a href="https://www.ifanr.com/1615566#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/58c6ee58f9a5a12d2f55eb3ae327303e.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615566?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
    <article class="article-item">
        <h3><a href="/article/966218811f9d6a23e9d30c868bbdbb22.html">iPhone 16e 上的这颗全新芯片，为什么值得苹果烧几十亿美元？</a></h3>
        <div class="article-meta">
            <span class="category">科技</span>
            <span class="date">Tue, 25 Feb 2025 07:03:52 +0000</span>
        </div>
        <div class="article-summary">
            Apple Silicon 再迎新成员<p>#欢迎关注爱范儿官方微信公众号：爱范儿（微信号：ifanr），更多精彩内容第一时间为您奉上。</p><p>
<a href="https://www.ifanr.com">爱范儿</a> |
<a href="https://www.ifanr.com/1615484">原文链接</a> ·
<a href="https://www.ifanr.com/1615484#comments">查看评论</a> ·
<a href="https://weibo.com/ifanr">新浪微博</a>
</p>

<br />
<div style="text-align: center; border-top: 1px dotted #ccc;">
</div>
        </div>
        <div class="article-link">
            <a href="/article/966218811f9d6a23e9d30c868bbdbb22.html">阅读全文</a>
            <a href="https://www.ifanr.com/1615484?utm_source=rss&utm_medium=rss&utm_campaign=" target="_blank">查看原文</a>
        </div>
    </article>
    
</div>

<div class="pagination">
    
    
    <span class="current">1 / 4</span>
    
    
    <a href="/index_2.html" class="next">下一页</a>
    
</div>

    </main>
    
    <footer>
        <div class="container">
            <p>© 2025-02-27 内容聚合平台 - 自动聚合各大网站优质内容</p>
            <p>生成时间: 2025-02-27 11:44:59</p>
        </div>
    </footer>

<!-- 百度联盟横幅广告 -->
<div style="margin: 10px auto; text-align: center;">
    <script type="text/javascript">
        (function() {
            var s = "_" + Math.random().toString(36).slice(2);
            document.write('<div id="' + s + '"></div>');
            (window.slotbydup=window.slotbydup || []).push({
                id: 'ele',
                container: s,
                size: '728,90',
                display: 'inlay-fix'
            });
        })();
    </script>
    <script type="text/javascript" src="//cpro.baidustatic.com/cpro/ui/c.js" async="async" defer="defer"></script>
</div>

</body>
</html>